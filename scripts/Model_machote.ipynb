{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib.colors import ListedColormap\n",
    "register_matplotlib_converters()\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# https://www.kaggle.com/marketneutral/purged-rolling-time-series-cv-split\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://www.kaggle.com/gogo827jz/jane-street-ffill-xgboost-purgedtimeseriescv\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "    jet = plt.cm.get_cmap('jet', 256)\n",
    "    seq = np.linspace(0, 1, 256)\n",
    "    _ = np.random.shuffle(seq)   # inplace\n",
    "    cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "forecast_1 = pd.read_csv('data/wind_challenge/Dataset1_forecast.csv')\n",
    "forecast_1['Time'] = pd.to_datetime(forecast_1['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_1 = pd.read_csv('data/wind_challenge/Dataset3_forecast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed/Datasets1_join.csv')\n",
    "df['timeStamp'] = pd.to_datetime(df['timeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>availableMW</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>windPower</th>\n",
       "      <th>Time</th>\n",
       "      <th>windSpeed (m/s)</th>\n",
       "      <th>windDic (degree)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>11.9</td>\n",
       "      <td>42.5118</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>9.50241</td>\n",
       "      <td>303.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:05:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.7067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:10:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.7067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>42.3044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:20:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>42.3044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01 00:25:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>43.3869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-01 00:30:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>43.3869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-01 00:35:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>43.2298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-01 00:40:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>43.2298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-01 00:45:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>43.2298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-01 00:50:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>43.2298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-01 00:55:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>44.0526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.1584</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>8.60719</td>\n",
       "      <td>301.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-01 01:05:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>44.5217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-01 01:10:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>44.5217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01 01:15:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>44.0526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-01 01:20:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>44.0526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-01 01:25:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>44.0526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-01 01:30:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>44.0526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-01 01:35:00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>12.7</td>\n",
       "      <td>43.8115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timeStamp  availableMW  windSpeed  windPower  \\\n",
       "0  2018-01-01 00:00:00         34.5       11.9    42.5118   \n",
       "1  2018-01-01 00:05:00         34.5       12.0    42.7067   \n",
       "2  2018-01-01 00:10:00         34.5       12.0    42.7067   \n",
       "3  2018-01-01 00:15:00         34.5       11.8    42.3044   \n",
       "4  2018-01-01 00:20:00         34.5       11.8    42.3044   \n",
       "5  2018-01-01 00:25:00         34.5       12.4    43.3869   \n",
       "6  2018-01-01 00:30:00         34.5       12.4    43.3869   \n",
       "7  2018-01-01 00:35:00         34.5       12.3    43.2298   \n",
       "8  2018-01-01 00:40:00         34.5       12.3    43.2298   \n",
       "9  2018-01-01 00:45:00         34.5       12.3    43.2298   \n",
       "10 2018-01-01 00:50:00         34.5       12.3    43.2298   \n",
       "11 2018-01-01 00:55:00         34.5       12.9    44.0526   \n",
       "12 2018-01-01 01:00:00         34.5       13.0    44.1584   \n",
       "13 2018-01-01 01:05:00         34.5       13.5    44.5217   \n",
       "14 2018-01-01 01:10:00         34.5       13.5    44.5217   \n",
       "15 2018-01-01 01:15:00         34.5       12.9    44.0526   \n",
       "16 2018-01-01 01:20:00         34.5       12.9    44.0526   \n",
       "17 2018-01-01 01:25:00         34.5       12.9    44.0526   \n",
       "18 2018-01-01 01:30:00         34.5       12.9    44.0526   \n",
       "19 2018-01-01 01:35:00         34.5       12.7    43.8115   \n",
       "\n",
       "                   Time  windSpeed (m/s)  windDic (degree)  \n",
       "0   2018-01-01 00:00:00          9.50241           303.854  \n",
       "1                   NaN              NaN               NaN  \n",
       "2                   NaN              NaN               NaN  \n",
       "3                   NaN              NaN               NaN  \n",
       "4                   NaN              NaN               NaN  \n",
       "5                   NaN              NaN               NaN  \n",
       "6                   NaN              NaN               NaN  \n",
       "7                   NaN              NaN               NaN  \n",
       "8                   NaN              NaN               NaN  \n",
       "9                   NaN              NaN               NaN  \n",
       "10                  NaN              NaN               NaN  \n",
       "11                  NaN              NaN               NaN  \n",
       "12  2018-01-01 01:00:00          8.60719           301.083  \n",
       "13                  NaN              NaN               NaN  \n",
       "14                  NaN              NaN               NaN  \n",
       "15                  NaN              NaN               NaN  \n",
       "16                  NaN              NaN               NaN  \n",
       "17                  NaN              NaN               NaN  \n",
       "18                  NaN              NaN               NaN  \n",
       "19                  NaN              NaN               NaN  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ebb13ba250>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['windSpeed (m/s)'], df['windSpeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.copy()\n",
    "train = train[['timeStamp', 'windSpeed (m/s)', 'windDic (degree)', 'windPower']]\n",
    "#speed = speed.set_index('Time')\n",
    "#speed = speed.asfreq('1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>windSpeed (m/s)</th>\n",
       "      <th>windDic (degree)</th>\n",
       "      <th>windPower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>9.502410</td>\n",
       "      <td>303.854000</td>\n",
       "      <td>42.5118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:05:00</td>\n",
       "      <td>9.427808</td>\n",
       "      <td>303.623083</td>\n",
       "      <td>42.7067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:10:00</td>\n",
       "      <td>9.353207</td>\n",
       "      <td>303.392167</td>\n",
       "      <td>42.7067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>9.278605</td>\n",
       "      <td>303.161250</td>\n",
       "      <td>42.3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:20:00</td>\n",
       "      <td>9.204003</td>\n",
       "      <td>302.930333</td>\n",
       "      <td>42.3044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timeStamp  windSpeed (m/s)  windDic (degree)  windPower\n",
       "0 2018-01-01 00:00:00         9.502410        303.854000    42.5118\n",
       "1 2018-01-01 00:05:00         9.427808        303.623083    42.7067\n",
       "2 2018-01-01 00:10:00         9.353207        303.392167    42.7067\n",
       "3 2018-01-01 00:15:00         9.278605        303.161250    42.3044\n",
       "4 2018-01-01 00:20:00         9.204003        302.930333    42.3044"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind speed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['y'] = train['windPower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['speed_lag_1'] = train['windSpeed (m/s)'].shift(1)\n",
    "train['speed_lag_2'] = train['windSpeed (m/s)'].shift(2)\n",
    "train['speed_lag_3'] = train['windSpeed (m/s)'].shift(3)\n",
    "train['speed_lag_4'] = train['windSpeed (m/s)'].shift(4)\n",
    "train['speed_lag_5'] = train['windSpeed (m/s)'].shift(5)\n",
    "train['speed_lag_6'] = train['windSpeed (m/s)'].shift(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['speed_rolling_6'] = train['windSpeed (m/s)'].rolling(6).mean()\n",
    "train['speed_rolling_12'] = train['windSpeed (m/s)'].rolling(12).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>windSpeed (m/s)</th>\n",
       "      <th>windDic (degree)</th>\n",
       "      <th>windPower</th>\n",
       "      <th>y</th>\n",
       "      <th>speed_lag_1</th>\n",
       "      <th>speed_lag_2</th>\n",
       "      <th>speed_lag_3</th>\n",
       "      <th>speed_lag_4</th>\n",
       "      <th>speed_lag_5</th>\n",
       "      <th>speed_lag_6</th>\n",
       "      <th>speed_rolling_6</th>\n",
       "      <th>speed_rolling_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>9.502410</td>\n",
       "      <td>303.854000</td>\n",
       "      <td>42.5118</td>\n",
       "      <td>42.5118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:05:00</td>\n",
       "      <td>9.427808</td>\n",
       "      <td>303.623083</td>\n",
       "      <td>42.7067</td>\n",
       "      <td>42.7067</td>\n",
       "      <td>9.502410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:10:00</td>\n",
       "      <td>9.353207</td>\n",
       "      <td>303.392167</td>\n",
       "      <td>42.7067</td>\n",
       "      <td>42.7067</td>\n",
       "      <td>9.427808</td>\n",
       "      <td>9.502410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>9.278605</td>\n",
       "      <td>303.161250</td>\n",
       "      <td>42.3044</td>\n",
       "      <td>42.3044</td>\n",
       "      <td>9.353207</td>\n",
       "      <td>9.427808</td>\n",
       "      <td>9.502410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:20:00</td>\n",
       "      <td>9.204003</td>\n",
       "      <td>302.930333</td>\n",
       "      <td>42.3044</td>\n",
       "      <td>42.3044</td>\n",
       "      <td>9.278605</td>\n",
       "      <td>9.353207</td>\n",
       "      <td>9.427808</td>\n",
       "      <td>9.502410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88936</th>\n",
       "      <td>2018-12-30 23:40:00</td>\n",
       "      <td>3.272611</td>\n",
       "      <td>170.965032</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.222482</td>\n",
       "      <td>3.172352</td>\n",
       "      <td>3.122222</td>\n",
       "      <td>3.072093</td>\n",
       "      <td>3.021963</td>\n",
       "      <td>2.971834</td>\n",
       "      <td>3.147287</td>\n",
       "      <td>2.973198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88937</th>\n",
       "      <td>2018-12-30 23:45:00</td>\n",
       "      <td>3.322741</td>\n",
       "      <td>171.568802</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.272611</td>\n",
       "      <td>3.222482</td>\n",
       "      <td>3.172352</td>\n",
       "      <td>3.122222</td>\n",
       "      <td>3.072093</td>\n",
       "      <td>3.021963</td>\n",
       "      <td>3.197417</td>\n",
       "      <td>3.035178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88938</th>\n",
       "      <td>2018-12-30 23:50:00</td>\n",
       "      <td>3.372871</td>\n",
       "      <td>172.172572</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.322741</td>\n",
       "      <td>3.272611</td>\n",
       "      <td>3.222482</td>\n",
       "      <td>3.172352</td>\n",
       "      <td>3.122222</td>\n",
       "      <td>3.072093</td>\n",
       "      <td>3.247547</td>\n",
       "      <td>3.093208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88939</th>\n",
       "      <td>2018-12-30 23:55:00</td>\n",
       "      <td>3.423000</td>\n",
       "      <td>172.776341</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.372871</td>\n",
       "      <td>3.322741</td>\n",
       "      <td>3.272611</td>\n",
       "      <td>3.222482</td>\n",
       "      <td>3.172352</td>\n",
       "      <td>3.122222</td>\n",
       "      <td>3.297676</td>\n",
       "      <td>3.147287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88940</th>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>3.473130</td>\n",
       "      <td>173.380111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.423000</td>\n",
       "      <td>3.372871</td>\n",
       "      <td>3.322741</td>\n",
       "      <td>3.272611</td>\n",
       "      <td>3.222482</td>\n",
       "      <td>3.172352</td>\n",
       "      <td>3.347806</td>\n",
       "      <td>3.197417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88941 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timeStamp  windSpeed (m/s)  windDic (degree)  windPower  \\\n",
       "0     2018-01-01 00:00:00         9.502410        303.854000    42.5118   \n",
       "1     2018-01-01 00:05:00         9.427808        303.623083    42.7067   \n",
       "2     2018-01-01 00:10:00         9.353207        303.392167    42.7067   \n",
       "3     2018-01-01 00:15:00         9.278605        303.161250    42.3044   \n",
       "4     2018-01-01 00:20:00         9.204003        302.930333    42.3044   \n",
       "...                   ...              ...               ...        ...   \n",
       "88936 2018-12-30 23:40:00         3.272611        170.965032     0.0000   \n",
       "88937 2018-12-30 23:45:00         3.322741        171.568802     0.0000   \n",
       "88938 2018-12-30 23:50:00         3.372871        172.172572     0.0000   \n",
       "88939 2018-12-30 23:55:00         3.423000        172.776341     0.0000   \n",
       "88940 2018-12-31 00:00:00         3.473130        173.380111     0.0000   \n",
       "\n",
       "             y  speed_lag_1  speed_lag_2  speed_lag_3  speed_lag_4  \\\n",
       "0      42.5118          NaN          NaN          NaN          NaN   \n",
       "1      42.7067     9.502410          NaN          NaN          NaN   \n",
       "2      42.7067     9.427808     9.502410          NaN          NaN   \n",
       "3      42.3044     9.353207     9.427808     9.502410          NaN   \n",
       "4      42.3044     9.278605     9.353207     9.427808     9.502410   \n",
       "...        ...          ...          ...          ...          ...   \n",
       "88936   0.0000     3.222482     3.172352     3.122222     3.072093   \n",
       "88937   0.0000     3.272611     3.222482     3.172352     3.122222   \n",
       "88938   0.0000     3.322741     3.272611     3.222482     3.172352   \n",
       "88939   0.0000     3.372871     3.322741     3.272611     3.222482   \n",
       "88940   0.0000     3.423000     3.372871     3.322741     3.272611   \n",
       "\n",
       "       speed_lag_5  speed_lag_6  speed_rolling_6  speed_rolling_12  \n",
       "0              NaN          NaN              NaN               NaN  \n",
       "1              NaN          NaN              NaN               NaN  \n",
       "2              NaN          NaN              NaN               NaN  \n",
       "3              NaN          NaN              NaN               NaN  \n",
       "4              NaN          NaN              NaN               NaN  \n",
       "...            ...          ...              ...               ...  \n",
       "88936     3.021963     2.971834         3.147287          2.973198  \n",
       "88937     3.072093     3.021963         3.197417          3.035178  \n",
       "88938     3.122222     3.072093         3.247547          3.093208  \n",
       "88939     3.172352     3.122222         3.297676          3.147287  \n",
       "88940     3.222482     3.172352         3.347806          3.197417  \n",
       "\n",
       "[88941 rows x 13 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = ['windDic (degree)', 'windSpeed (m/s)', 'speed_lag_1',\n",
    "       'speed_lag_2', 'speed_lag_3', 'speed_lag_4', 'speed_lag_5',\n",
    "       'speed_lag_6', 'speed_rolling_6', 'speed_rolling_12']\n",
    "y_list = ['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[X_list].values\n",
    "y = train[y_list].values.ravel()\n",
    "dates = train[\"timeStamp\"].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-01-01T00:00:00.000000000', '2018-01-01T00:05:00.000000000',\n",
       "       '2018-01-01T00:10:00.000000000', ...,\n",
       "       '2018-12-30T23:50:00.000000000', '2018-12-30T23:55:00.000000000',\n",
       "       '2018-12-31T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict = {\n",
    "    \"PurgedCV\": PurgedGroupTimeSeriesSplit(n_splits=5, \n",
    "                                           group_gap=0, \n",
    "                                           max_train_group_size=15000, \n",
    "                                           max_test_group_size=5000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cv = cv_dict[\"PurgedCV\"]\n",
    "plot_cv_indices(cv, X, y, dates, ax, 5, lw = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Función para evaluar el modelo\n",
    "def utility(estimator, X, y):\n",
    "    \"\"\"Custom scoring object as per documentation:\n",
    "    https://scikit-learn.org/stable/modules/model_evaluation.html#implementing-your-own-scoring-object\n",
    "    Utility score formulae are defined in competition's intro:\n",
    "    https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "    Using optimisation tricks from @gogo827jz:\n",
    "    https://www.kaggle.com/c/jane-street-market-prediction/discussion/201257\n",
    "    \"\"\"\n",
    "\n",
    "    # still looking for a way to write this for xgb.cv but it passes DMatrix which doesn't allow indexing...\n",
    "    # https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html\n",
    "\n",
    "    \n",
    "    prediction = estimator.predict(X)\n",
    "    #proba = estimator.predict_proba(X)[:, 1]\n",
    "    mse = mean_squared_error(y, prediction)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = dict(#num_leaves=31, \n",
    "                       max_depth=7, \n",
    "                       learning_rate=0.01, \n",
    "                       n_estimators=200, \n",
    "                       objective=\"regression\", \n",
    "                       min_child_weight=0.001, min_child_samples=20, \n",
    "                       subsample=1.0, subsample_freq=0, \n",
    "                       colsample_bytree=0.8, \n",
    "                       reg_alpha=1, reg_lambda=1, \n",
    "                       random_state=2, \n",
    "                       n_jobs=-1, \n",
    "                       silent=True, \n",
    "                       importance_type='split'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [5, 7, 8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********  PurgedCV  **********\n",
      "***** Depth:  5  *****\n",
      "Fold 0 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.516\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 207.425\n",
      "[3]\tvalid_0's l2: 205.342\n",
      "[4]\tvalid_0's l2: 203.307\n",
      "[5]\tvalid_0's l2: 201.369\n",
      "[6]\tvalid_0's l2: 199.441\n",
      "[7]\tvalid_0's l2: 197.562\n",
      "[8]\tvalid_0's l2: 195.765\n",
      "[9]\tvalid_0's l2: 193.983\n",
      "[10]\tvalid_0's l2: 192.234\n",
      "[11]\tvalid_0's l2: 190.55\n",
      "[12]\tvalid_0's l2: 188.889\n",
      "[13]\tvalid_0's l2: 187.249\n",
      "[14]\tvalid_0's l2: 185.715\n",
      "[15]\tvalid_0's l2: 184.181\n",
      "[16]\tvalid_0's l2: 182.675\n",
      "[17]\tvalid_0's l2: 181.249\n",
      "[18]\tvalid_0's l2: 179.841\n",
      "[19]\tvalid_0's l2: 178.4\n",
      "[20]\tvalid_0's l2: 177.085\n",
      "[21]\tvalid_0's l2: 175.734\n",
      "[22]\tvalid_0's l2: 174.518\n",
      "[23]\tvalid_0's l2: 173.273\n",
      "[24]\tvalid_0's l2: 172.102\n",
      "[25]\tvalid_0's l2: 170.97\n",
      "[26]\tvalid_0's l2: 169.831\n",
      "[27]\tvalid_0's l2: 168.757\n",
      "[28]\tvalid_0's l2: 167.617\n",
      "[29]\tvalid_0's l2: 166.538\n",
      "[30]\tvalid_0's l2: 165.471\n",
      "[31]\tvalid_0's l2: 164.519\n",
      "[32]\tvalid_0's l2: 163.52\n",
      "[33]\tvalid_0's l2: 162.528\n",
      "[34]\tvalid_0's l2: 161.58\n",
      "[35]\tvalid_0's l2: 160.729\n",
      "[36]\tvalid_0's l2: 159.911\n",
      "[37]\tvalid_0's l2: 159.115\n",
      "[38]\tvalid_0's l2: 158.29\n",
      "[39]\tvalid_0's l2: 157.539\n",
      "[40]\tvalid_0's l2: 156.835\n",
      "[41]\tvalid_0's l2: 156.12\n",
      "[42]\tvalid_0's l2: 155.361\n",
      "[43]\tvalid_0's l2: 154.638\n",
      "[44]\tvalid_0's l2: 153.917\n",
      "[45]\tvalid_0's l2: 153.215\n",
      "[46]\tvalid_0's l2: 152.613\n",
      "[47]\tvalid_0's l2: 152.043\n",
      "[48]\tvalid_0's l2: 151.46\n",
      "[49]\tvalid_0's l2: 150.907\n",
      "[50]\tvalid_0's l2: 150.309\n",
      "[51]\tvalid_0's l2: 149.803\n",
      "[52]\tvalid_0's l2: 149.303\n",
      "[53]\tvalid_0's l2: 148.819\n",
      "[54]\tvalid_0's l2: 148.332\n",
      "[55]\tvalid_0's l2: 147.879\n",
      "[56]\tvalid_0's l2: 147.387\n",
      "[57]\tvalid_0's l2: 147.007\n",
      "[58]\tvalid_0's l2: 146.605\n",
      "[59]\tvalid_0's l2: 146.156\n",
      "[60]\tvalid_0's l2: 145.787\n",
      "[61]\tvalid_0's l2: 145.435\n",
      "[62]\tvalid_0's l2: 145.085\n",
      "[63]\tvalid_0's l2: 144.745\n",
      "[64]\tvalid_0's l2: 144.389\n",
      "[65]\tvalid_0's l2: 144.087\n",
      "[66]\tvalid_0's l2: 143.799\n",
      "[67]\tvalid_0's l2: 143.524\n",
      "[68]\tvalid_0's l2: 143.247\n",
      "[69]\tvalid_0's l2: 142.97\n",
      "[70]\tvalid_0's l2: 142.728\n",
      "[71]\tvalid_0's l2: 142.493\n",
      "[72]\tvalid_0's l2: 142.258\n",
      "[73]\tvalid_0's l2: 141.986\n",
      "[74]\tvalid_0's l2: 141.796\n",
      "[75]\tvalid_0's l2: 141.613\n",
      "[76]\tvalid_0's l2: 141.387\n",
      "[77]\tvalid_0's l2: 141.189\n",
      "[78]\tvalid_0's l2: 141.056\n",
      "[79]\tvalid_0's l2: 140.853\n",
      "[80]\tvalid_0's l2: 140.699\n",
      "[81]\tvalid_0's l2: 140.549\n",
      "[82]\tvalid_0's l2: 140.416\n",
      "[83]\tvalid_0's l2: 140.319\n",
      "[84]\tvalid_0's l2: 140.197\n",
      "[85]\tvalid_0's l2: 140.093\n",
      "[86]\tvalid_0's l2: 140.019\n",
      "[87]\tvalid_0's l2: 139.945\n",
      "[88]\tvalid_0's l2: 139.891\n",
      "[89]\tvalid_0's l2: 139.793\n",
      "[90]\tvalid_0's l2: 139.745\n",
      "[91]\tvalid_0's l2: 139.672\n",
      "[92]\tvalid_0's l2: 139.588\n",
      "[93]\tvalid_0's l2: 139.503\n",
      "[94]\tvalid_0's l2: 139.448\n",
      "[95]\tvalid_0's l2: 139.378\n",
      "[96]\tvalid_0's l2: 139.375\n",
      "[97]\tvalid_0's l2: 139.315\n",
      "[98]\tvalid_0's l2: 139.275\n",
      "[99]\tvalid_0's l2: 139.236\n",
      "[100]\tvalid_0's l2: 139.207\n",
      "[101]\tvalid_0's l2: 139.185\n",
      "[102]\tvalid_0's l2: 139.185\n",
      "[103]\tvalid_0's l2: 139.147\n",
      "[104]\tvalid_0's l2: 139.139\n",
      "[105]\tvalid_0's l2: 139.159\n",
      "[106]\tvalid_0's l2: 139.135\n",
      "[107]\tvalid_0's l2: 139.131\n",
      "[108]\tvalid_0's l2: 139.117\n",
      "[109]\tvalid_0's l2: 139.109\n",
      "[110]\tvalid_0's l2: 139.118\n",
      "[111]\tvalid_0's l2: 139.164\n",
      "[112]\tvalid_0's l2: 139.231\n",
      "[113]\tvalid_0's l2: 139.247\n",
      "[114]\tvalid_0's l2: 139.298\n",
      "[115]\tvalid_0's l2: 139.364\n",
      "[116]\tvalid_0's l2: 139.425\n",
      "[117]\tvalid_0's l2: 139.502\n",
      "[118]\tvalid_0's l2: 139.554\n",
      "[119]\tvalid_0's l2: 139.581\n",
      "[120]\tvalid_0's l2: 139.676\n",
      "[121]\tvalid_0's l2: 139.785\n",
      "[122]\tvalid_0's l2: 139.9\n",
      "[123]\tvalid_0's l2: 139.97\n",
      "[124]\tvalid_0's l2: 140.091\n",
      "[125]\tvalid_0's l2: 140.203\n",
      "[126]\tvalid_0's l2: 140.312\n",
      "[127]\tvalid_0's l2: 140.393\n",
      "[128]\tvalid_0's l2: 140.508\n",
      "[129]\tvalid_0's l2: 140.551\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's l2: 139.109\n",
      "Training Iteration:  109\n",
      "Train:\tValid:\tFold 1 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.394\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 207.321\n",
      "[3]\tvalid_0's l2: 205.169\n",
      "[4]\tvalid_0's l2: 203.068\n",
      "[5]\tvalid_0's l2: 201.123\n",
      "[6]\tvalid_0's l2: 199.108\n",
      "[7]\tvalid_0's l2: 197.141\n",
      "[8]\tvalid_0's l2: 195.318\n",
      "[9]\tvalid_0's l2: 193.433\n",
      "[10]\tvalid_0's l2: 191.586\n",
      "[11]\tvalid_0's l2: 189.783\n",
      "[12]\tvalid_0's l2: 188.019\n",
      "[13]\tvalid_0's l2: 186.292\n",
      "[14]\tvalid_0's l2: 184.696\n",
      "[15]\tvalid_0's l2: 183.046\n",
      "[16]\tvalid_0's l2: 181.426\n",
      "[17]\tvalid_0's l2: 179.843\n",
      "[18]\tvalid_0's l2: 178.299\n",
      "[19]\tvalid_0's l2: 176.789\n",
      "[20]\tvalid_0's l2: 175.316\n",
      "[21]\tvalid_0's l2: 173.878\n",
      "[22]\tvalid_0's l2: 172.525\n",
      "[23]\tvalid_0's l2: 171.086\n",
      "[24]\tvalid_0's l2: 169.793\n",
      "[25]\tvalid_0's l2: 168.463\n",
      "[26]\tvalid_0's l2: 167.114\n",
      "[27]\tvalid_0's l2: 165.856\n",
      "[28]\tvalid_0's l2: 164.569\n",
      "[29]\tvalid_0's l2: 163.32\n",
      "[30]\tvalid_0's l2: 162.144\n",
      "[31]\tvalid_0's l2: 160.995\n",
      "[32]\tvalid_0's l2: 159.812\n",
      "[33]\tvalid_0's l2: 158.673\n",
      "[34]\tvalid_0's l2: 157.585\n",
      "[35]\tvalid_0's l2: 156.57\n",
      "[36]\tvalid_0's l2: 155.579\n",
      "[37]\tvalid_0's l2: 154.538\n",
      "[38]\tvalid_0's l2: 153.51\n",
      "[39]\tvalid_0's l2: 152.581\n",
      "[40]\tvalid_0's l2: 151.64\n",
      "[41]\tvalid_0's l2: 150.751\n",
      "[42]\tvalid_0's l2: 149.842\n",
      "[43]\tvalid_0's l2: 148.928\n",
      "[44]\tvalid_0's l2: 148.084\n",
      "[45]\tvalid_0's l2: 147.255\n",
      "[46]\tvalid_0's l2: 146.389\n",
      "[47]\tvalid_0's l2: 145.549\n",
      "[48]\tvalid_0's l2: 144.739\n",
      "[49]\tvalid_0's l2: 143.998\n",
      "[50]\tvalid_0's l2: 143.218\n",
      "[51]\tvalid_0's l2: 142.501\n",
      "[52]\tvalid_0's l2: 141.803\n",
      "[53]\tvalid_0's l2: 141.051\n",
      "[54]\tvalid_0's l2: 140.381\n",
      "[55]\tvalid_0's l2: 139.68\n",
      "[56]\tvalid_0's l2: 139.053\n",
      "[57]\tvalid_0's l2: 138.435\n",
      "[58]\tvalid_0's l2: 137.818\n",
      "[59]\tvalid_0's l2: 137.181\n",
      "[60]\tvalid_0's l2: 136.599\n",
      "[61]\tvalid_0's l2: 135.989\n",
      "[62]\tvalid_0's l2: 135.439\n",
      "[63]\tvalid_0's l2: 134.89\n",
      "[64]\tvalid_0's l2: 134.356\n",
      "[65]\tvalid_0's l2: 133.801\n",
      "[66]\tvalid_0's l2: 133.298\n",
      "[67]\tvalid_0's l2: 132.765\n",
      "[68]\tvalid_0's l2: 132.217\n",
      "[69]\tvalid_0's l2: 131.604\n",
      "[70]\tvalid_0's l2: 130.977\n",
      "[71]\tvalid_0's l2: 130.363\n",
      "[72]\tvalid_0's l2: 129.928\n",
      "[73]\tvalid_0's l2: 129.375\n",
      "[74]\tvalid_0's l2: 128.797\n",
      "[75]\tvalid_0's l2: 128.266\n",
      "[76]\tvalid_0's l2: 127.733\n",
      "[77]\tvalid_0's l2: 127.338\n",
      "[78]\tvalid_0's l2: 126.836\n",
      "[79]\tvalid_0's l2: 126.314\n",
      "[80]\tvalid_0's l2: 125.839\n",
      "[81]\tvalid_0's l2: 125.465\n",
      "[82]\tvalid_0's l2: 125.021\n",
      "[83]\tvalid_0's l2: 124.624\n",
      "[84]\tvalid_0's l2: 124.193\n",
      "[85]\tvalid_0's l2: 123.688\n",
      "[86]\tvalid_0's l2: 123.365\n",
      "[87]\tvalid_0's l2: 122.876\n",
      "[88]\tvalid_0's l2: 122.548\n",
      "[89]\tvalid_0's l2: 122.263\n",
      "[90]\tvalid_0's l2: 121.855\n",
      "[91]\tvalid_0's l2: 121.551\n",
      "[92]\tvalid_0's l2: 121.2\n",
      "[93]\tvalid_0's l2: 120.844\n",
      "[94]\tvalid_0's l2: 120.442\n",
      "[95]\tvalid_0's l2: 120.125\n",
      "[96]\tvalid_0's l2: 119.773\n",
      "[97]\tvalid_0's l2: 119.51\n",
      "[98]\tvalid_0's l2: 119.274\n",
      "[99]\tvalid_0's l2: 119.053\n",
      "[100]\tvalid_0's l2: 118.83\n",
      "[101]\tvalid_0's l2: 118.48\n",
      "[102]\tvalid_0's l2: 118.243\n",
      "[103]\tvalid_0's l2: 118.044\n",
      "[104]\tvalid_0's l2: 117.846\n",
      "[105]\tvalid_0's l2: 117.622\n",
      "[106]\tvalid_0's l2: 117.441\n",
      "[107]\tvalid_0's l2: 117.261\n",
      "[108]\tvalid_0's l2: 117.09\n",
      "[109]\tvalid_0's l2: 116.926\n",
      "[110]\tvalid_0's l2: 116.761\n",
      "[111]\tvalid_0's l2: 116.614\n",
      "[112]\tvalid_0's l2: 116.45\n",
      "[113]\tvalid_0's l2: 116.3\n",
      "[114]\tvalid_0's l2: 116.147\n",
      "[115]\tvalid_0's l2: 115.958\n",
      "[116]\tvalid_0's l2: 115.825\n",
      "[117]\tvalid_0's l2: 115.694\n",
      "[118]\tvalid_0's l2: 115.448\n",
      "[119]\tvalid_0's l2: 115.322\n",
      "[120]\tvalid_0's l2: 115.206\n",
      "[121]\tvalid_0's l2: 115.075\n",
      "[122]\tvalid_0's l2: 114.963\n",
      "[123]\tvalid_0's l2: 114.902\n",
      "[124]\tvalid_0's l2: 114.802\n",
      "[125]\tvalid_0's l2: 114.707\n",
      "[126]\tvalid_0's l2: 114.626\n",
      "[127]\tvalid_0's l2: 114.435\n",
      "[128]\tvalid_0's l2: 114.33\n",
      "[129]\tvalid_0's l2: 114.237\n",
      "[130]\tvalid_0's l2: 114.178\n",
      "[131]\tvalid_0's l2: 114.09\n",
      "[132]\tvalid_0's l2: 114.031\n",
      "[133]\tvalid_0's l2: 113.95\n",
      "[134]\tvalid_0's l2: 113.883\n",
      "[135]\tvalid_0's l2: 113.728\n",
      "[136]\tvalid_0's l2: 113.64\n",
      "[137]\tvalid_0's l2: 113.572\n",
      "[138]\tvalid_0's l2: 113.465\n",
      "[139]\tvalid_0's l2: 113.416\n",
      "[140]\tvalid_0's l2: 113.305\n",
      "[141]\tvalid_0's l2: 113.167\n",
      "[142]\tvalid_0's l2: 113.107\n",
      "[143]\tvalid_0's l2: 113.033\n",
      "[144]\tvalid_0's l2: 113.005\n",
      "[145]\tvalid_0's l2: 112.947\n",
      "[146]\tvalid_0's l2: 112.881\n",
      "[147]\tvalid_0's l2: 112.801\n",
      "[148]\tvalid_0's l2: 112.725\n",
      "[149]\tvalid_0's l2: 112.58\n",
      "[150]\tvalid_0's l2: 112.506\n",
      "[151]\tvalid_0's l2: 112.443\n",
      "[152]\tvalid_0's l2: 112.4\n",
      "[153]\tvalid_0's l2: 112.371\n",
      "[154]\tvalid_0's l2: 112.294\n",
      "[155]\tvalid_0's l2: 112.14\n",
      "[156]\tvalid_0's l2: 112.059\n",
      "[157]\tvalid_0's l2: 111.994\n",
      "[158]\tvalid_0's l2: 111.875\n",
      "[159]\tvalid_0's l2: 111.847\n",
      "[160]\tvalid_0's l2: 111.832\n",
      "[161]\tvalid_0's l2: 111.771\n",
      "[162]\tvalid_0's l2: 111.64\n",
      "[163]\tvalid_0's l2: 111.626\n",
      "[164]\tvalid_0's l2: 111.457\n",
      "[165]\tvalid_0's l2: 111.461\n",
      "[166]\tvalid_0's l2: 111.427\n",
      "[167]\tvalid_0's l2: 111.391\n",
      "[168]\tvalid_0's l2: 111.303\n",
      "[169]\tvalid_0's l2: 111.214\n",
      "[170]\tvalid_0's l2: 111.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171]\tvalid_0's l2: 111.175\n",
      "[172]\tvalid_0's l2: 111.052\n",
      "[173]\tvalid_0's l2: 111.036\n",
      "[174]\tvalid_0's l2: 110.984\n",
      "[175]\tvalid_0's l2: 110.936\n",
      "[176]\tvalid_0's l2: 110.889\n",
      "[177]\tvalid_0's l2: 110.788\n",
      "[178]\tvalid_0's l2: 110.825\n",
      "[179]\tvalid_0's l2: 110.744\n",
      "[180]\tvalid_0's l2: 110.719\n",
      "[181]\tvalid_0's l2: 110.648\n",
      "[182]\tvalid_0's l2: 110.617\n",
      "[183]\tvalid_0's l2: 110.514\n",
      "[184]\tvalid_0's l2: 110.488\n",
      "[185]\tvalid_0's l2: 110.512\n",
      "[186]\tvalid_0's l2: 110.456\n",
      "[187]\tvalid_0's l2: 110.389\n",
      "[188]\tvalid_0's l2: 110.38\n",
      "[189]\tvalid_0's l2: 110.321\n",
      "[190]\tvalid_0's l2: 110.267\n",
      "[191]\tvalid_0's l2: 110.237\n",
      "[192]\tvalid_0's l2: 110.24\n",
      "[193]\tvalid_0's l2: 110.188\n",
      "[194]\tvalid_0's l2: 110.111\n",
      "[195]\tvalid_0's l2: 110.121\n",
      "[196]\tvalid_0's l2: 110.126\n",
      "[197]\tvalid_0's l2: 110.072\n",
      "[198]\tvalid_0's l2: 110.072\n",
      "[199]\tvalid_0's l2: 110.029\n",
      "[200]\tvalid_0's l2: 109.974\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 109.974\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 2 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 173.702\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 171.892\n",
      "[3]\tvalid_0's l2: 169.89\n",
      "[4]\tvalid_0's l2: 167.929\n",
      "[5]\tvalid_0's l2: 166.216\n",
      "[6]\tvalid_0's l2: 164.327\n",
      "[7]\tvalid_0's l2: 162.472\n",
      "[8]\tvalid_0's l2: 160.863\n",
      "[9]\tvalid_0's l2: 159.082\n",
      "[10]\tvalid_0's l2: 157.323\n",
      "[11]\tvalid_0's l2: 155.603\n",
      "[12]\tvalid_0's l2: 153.92\n",
      "[13]\tvalid_0's l2: 152.273\n",
      "[14]\tvalid_0's l2: 150.852\n",
      "[15]\tvalid_0's l2: 149.27\n",
      "[16]\tvalid_0's l2: 147.712\n",
      "[17]\tvalid_0's l2: 146.191\n",
      "[18]\tvalid_0's l2: 144.69\n",
      "[19]\tvalid_0's l2: 143.224\n",
      "[20]\tvalid_0's l2: 141.811\n",
      "[21]\tvalid_0's l2: 140.401\n",
      "[22]\tvalid_0's l2: 139.187\n",
      "[23]\tvalid_0's l2: 137.857\n",
      "[24]\tvalid_0's l2: 136.695\n",
      "[25]\tvalid_0's l2: 135.394\n",
      "[26]\tvalid_0's l2: 134.122\n",
      "[27]\tvalid_0's l2: 132.877\n",
      "[28]\tvalid_0's l2: 131.673\n",
      "[29]\tvalid_0's l2: 130.474\n",
      "[30]\tvalid_0's l2: 129.329\n",
      "[31]\tvalid_0's l2: 128.179\n",
      "[32]\tvalid_0's l2: 127.073\n",
      "[33]\tvalid_0's l2: 125.974\n",
      "[34]\tvalid_0's l2: 124.903\n",
      "[35]\tvalid_0's l2: 123.972\n",
      "[36]\tvalid_0's l2: 123.058\n",
      "[37]\tvalid_0's l2: 122.029\n",
      "[38]\tvalid_0's l2: 121.03\n",
      "[39]\tvalid_0's l2: 120.176\n",
      "[40]\tvalid_0's l2: 119.22\n",
      "[41]\tvalid_0's l2: 118.4\n",
      "[42]\tvalid_0's l2: 117.482\n",
      "[43]\tvalid_0's l2: 116.589\n",
      "[44]\tvalid_0's l2: 115.701\n",
      "[45]\tvalid_0's l2: 114.841\n",
      "[46]\tvalid_0's l2: 113.98\n",
      "[47]\tvalid_0's l2: 113.162\n",
      "[48]\tvalid_0's l2: 112.334\n",
      "[49]\tvalid_0's l2: 111.544\n",
      "[50]\tvalid_0's l2: 110.768\n",
      "[51]\tvalid_0's l2: 110.103\n",
      "[52]\tvalid_0's l2: 109.365\n",
      "[53]\tvalid_0's l2: 108.631\n",
      "[54]\tvalid_0's l2: 108.005\n",
      "[55]\tvalid_0's l2: 107.294\n",
      "[56]\tvalid_0's l2: 106.601\n",
      "[57]\tvalid_0's l2: 105.942\n",
      "[58]\tvalid_0's l2: 105.36\n",
      "[59]\tvalid_0's l2: 104.697\n",
      "[60]\tvalid_0's l2: 104.145\n",
      "[61]\tvalid_0's l2: 103.505\n",
      "[62]\tvalid_0's l2: 102.887\n",
      "[63]\tvalid_0's l2: 102.36\n",
      "[64]\tvalid_0's l2: 101.846\n",
      "[65]\tvalid_0's l2: 101.223\n",
      "[66]\tvalid_0's l2: 100.654\n",
      "[67]\tvalid_0's l2: 100.086\n",
      "[68]\tvalid_0's l2: 99.4987\n",
      "[69]\tvalid_0's l2: 98.9621\n",
      "[70]\tvalid_0's l2: 98.4062\n",
      "[71]\tvalid_0's l2: 97.8308\n",
      "[72]\tvalid_0's l2: 97.3921\n",
      "[73]\tvalid_0's l2: 96.8372\n",
      "[74]\tvalid_0's l2: 96.3196\n",
      "[75]\tvalid_0's l2: 95.7869\n",
      "[76]\tvalid_0's l2: 95.2594\n",
      "[77]\tvalid_0's l2: 94.8681\n",
      "[78]\tvalid_0's l2: 94.3596\n",
      "[79]\tvalid_0's l2: 93.8968\n",
      "[80]\tvalid_0's l2: 93.3981\n",
      "[81]\tvalid_0's l2: 92.9409\n",
      "[82]\tvalid_0's l2: 92.4981\n",
      "[83]\tvalid_0's l2: 92.071\n",
      "[84]\tvalid_0's l2: 91.681\n",
      "[85]\tvalid_0's l2: 91.2473\n",
      "[86]\tvalid_0's l2: 90.8478\n",
      "[87]\tvalid_0's l2: 90.4102\n",
      "[88]\tvalid_0's l2: 90.0281\n",
      "[89]\tvalid_0's l2: 89.7147\n",
      "[90]\tvalid_0's l2: 89.3099\n",
      "[91]\tvalid_0's l2: 88.9266\n",
      "[92]\tvalid_0's l2: 88.5723\n",
      "[93]\tvalid_0's l2: 88.2147\n",
      "[94]\tvalid_0's l2: 87.8595\n",
      "[95]\tvalid_0's l2: 87.501\n",
      "[96]\tvalid_0's l2: 87.1357\n",
      "[97]\tvalid_0's l2: 86.8158\n",
      "[98]\tvalid_0's l2: 86.56\n",
      "[99]\tvalid_0's l2: 86.3136\n",
      "[100]\tvalid_0's l2: 86.0716\n",
      "[101]\tvalid_0's l2: 85.7159\n",
      "[102]\tvalid_0's l2: 85.4208\n",
      "[103]\tvalid_0's l2: 85.1176\n",
      "[104]\tvalid_0's l2: 84.8888\n",
      "[105]\tvalid_0's l2: 84.5601\n",
      "[106]\tvalid_0's l2: 84.3496\n",
      "[107]\tvalid_0's l2: 84.138\n",
      "[108]\tvalid_0's l2: 83.9322\n",
      "[109]\tvalid_0's l2: 83.7282\n",
      "[110]\tvalid_0's l2: 83.5317\n",
      "[111]\tvalid_0's l2: 83.2196\n",
      "[112]\tvalid_0's l2: 82.9275\n",
      "[113]\tvalid_0's l2: 82.7404\n",
      "[114]\tvalid_0's l2: 82.4614\n",
      "[115]\tvalid_0's l2: 82.172\n",
      "[116]\tvalid_0's l2: 81.9115\n",
      "[117]\tvalid_0's l2: 81.6554\n",
      "[118]\tvalid_0's l2: 81.4047\n",
      "[119]\tvalid_0's l2: 81.1487\n",
      "[120]\tvalid_0's l2: 80.9385\n",
      "[121]\tvalid_0's l2: 80.6812\n",
      "[122]\tvalid_0's l2: 80.448\n",
      "[123]\tvalid_0's l2: 80.2552\n",
      "[124]\tvalid_0's l2: 79.9943\n",
      "[125]\tvalid_0's l2: 79.7745\n",
      "[126]\tvalid_0's l2: 79.5586\n",
      "[127]\tvalid_0's l2: 79.345\n",
      "[128]\tvalid_0's l2: 79.0927\n",
      "[129]\tvalid_0's l2: 78.9572\n",
      "[130]\tvalid_0's l2: 78.7226\n",
      "[131]\tvalid_0's l2: 78.5885\n",
      "[132]\tvalid_0's l2: 78.3362\n",
      "[133]\tvalid_0's l2: 78.1435\n",
      "[134]\tvalid_0's l2: 77.9091\n",
      "[135]\tvalid_0's l2: 77.7617\n",
      "[136]\tvalid_0's l2: 77.6436\n",
      "[137]\tvalid_0's l2: 77.426\n",
      "[138]\tvalid_0's l2: 77.2428\n",
      "[139]\tvalid_0's l2: 77.0942\n",
      "[140]\tvalid_0's l2: 76.9003\n",
      "[141]\tvalid_0's l2: 76.7288\n",
      "[142]\tvalid_0's l2: 76.6281\n",
      "[143]\tvalid_0's l2: 76.5288\n",
      "[144]\tvalid_0's l2: 76.3181\n",
      "[145]\tvalid_0's l2: 76.2177\n",
      "[146]\tvalid_0's l2: 76.1157\n",
      "[147]\tvalid_0's l2: 75.9689\n",
      "[148]\tvalid_0's l2: 75.7735\n",
      "[149]\tvalid_0's l2: 75.6185\n",
      "[150]\tvalid_0's l2: 75.452\n",
      "[151]\tvalid_0's l2: 75.3014\n",
      "[152]\tvalid_0's l2: 75.2166\n",
      "[153]\tvalid_0's l2: 75.0443\n",
      "[154]\tvalid_0's l2: 74.9107\n",
      "[155]\tvalid_0's l2: 74.7995\n",
      "[156]\tvalid_0's l2: 74.6449\n",
      "[157]\tvalid_0's l2: 74.4812\n",
      "[158]\tvalid_0's l2: 74.3446\n",
      "[159]\tvalid_0's l2: 74.2704\n",
      "[160]\tvalid_0's l2: 74.1246\n",
      "[161]\tvalid_0's l2: 74.0199\n",
      "[162]\tvalid_0's l2: 73.9281\n",
      "[163]\tvalid_0's l2: 73.7993\n",
      "[164]\tvalid_0's l2: 73.6451\n",
      "[165]\tvalid_0's l2: 73.5311\n",
      "[166]\tvalid_0's l2: 73.394\n",
      "[167]\tvalid_0's l2: 73.3294\n",
      "[168]\tvalid_0's l2: 73.2245\n",
      "[169]\tvalid_0's l2: 73.097\n",
      "[170]\tvalid_0's l2: 72.995\n",
      "[171]\tvalid_0's l2: 72.88\n",
      "[172]\tvalid_0's l2: 72.7602\n",
      "[173]\tvalid_0's l2: 72.7047\n",
      "[174]\tvalid_0's l2: 72.6109\n",
      "[175]\tvalid_0's l2: 72.4962\n",
      "[176]\tvalid_0's l2: 72.4455\n",
      "[177]\tvalid_0's l2: 72.3544\n",
      "[178]\tvalid_0's l2: 72.2463\n",
      "[179]\tvalid_0's l2: 72.1808\n",
      "[180]\tvalid_0's l2: 72.1215\n",
      "[181]\tvalid_0's l2: 72.0129\n",
      "[182]\tvalid_0's l2: 71.9097\n",
      "[183]\tvalid_0's l2: 71.8453\n",
      "[184]\tvalid_0's l2: 71.8099\n",
      "[185]\tvalid_0's l2: 71.7121\n",
      "[186]\tvalid_0's l2: 71.6199\n",
      "[187]\tvalid_0's l2: 71.552\n",
      "[188]\tvalid_0's l2: 71.4679\n",
      "[189]\tvalid_0's l2: 71.3795\n",
      "[190]\tvalid_0's l2: 71.2876\n",
      "[191]\tvalid_0's l2: 71.2567\n",
      "[192]\tvalid_0's l2: 71.2167\n",
      "[193]\tvalid_0's l2: 71.1286\n",
      "[194]\tvalid_0's l2: 71.072\n",
      "[195]\tvalid_0's l2: 70.9958\n",
      "[196]\tvalid_0's l2: 70.8978\n",
      "[197]\tvalid_0's l2: 70.7964\n",
      "[198]\tvalid_0's l2: 70.7166\n",
      "[199]\tvalid_0's l2: 70.6763\n",
      "[200]\tvalid_0's l2: 70.5975\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 70.5975\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 3 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 183.99\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 181.672\n",
      "[3]\tvalid_0's l2: 179.408\n",
      "[4]\tvalid_0's l2: 177.19\n",
      "[5]\tvalid_0's l2: 175\n",
      "[6]\tvalid_0's l2: 172.868\n",
      "[7]\tvalid_0's l2: 170.778\n",
      "[8]\tvalid_0's l2: 168.714\n",
      "[9]\tvalid_0's l2: 166.705\n",
      "[10]\tvalid_0's l2: 164.747\n",
      "[11]\tvalid_0's l2: 162.828\n",
      "[12]\tvalid_0's l2: 160.937\n",
      "[13]\tvalid_0's l2: 159.091\n",
      "[14]\tvalid_0's l2: 157.267\n",
      "[15]\tvalid_0's l2: 155.49\n",
      "[16]\tvalid_0's l2: 153.739\n",
      "[17]\tvalid_0's l2: 152.032\n",
      "[18]\tvalid_0's l2: 150.356\n",
      "[19]\tvalid_0's l2: 148.662\n",
      "[20]\tvalid_0's l2: 147.039\n",
      "[21]\tvalid_0's l2: 145.462\n",
      "[22]\tvalid_0's l2: 143.866\n",
      "[23]\tvalid_0's l2: 142.381\n",
      "[24]\tvalid_0's l2: 140.842\n",
      "[25]\tvalid_0's l2: 139.367\n",
      "[26]\tvalid_0's l2: 137.978\n",
      "[27]\tvalid_0's l2: 136.572\n",
      "[28]\tvalid_0's l2: 135.192\n",
      "[29]\tvalid_0's l2: 133.787\n",
      "[30]\tvalid_0's l2: 132.453\n",
      "[31]\tvalid_0's l2: 131.152\n",
      "[32]\tvalid_0's l2: 129.854\n",
      "[33]\tvalid_0's l2: 128.547\n",
      "[34]\tvalid_0's l2: 127.323\n",
      "[35]\tvalid_0's l2: 126.073\n",
      "[36]\tvalid_0's l2: 124.854\n",
      "[37]\tvalid_0's l2: 123.73\n",
      "[38]\tvalid_0's l2: 122.597\n",
      "[39]\tvalid_0's l2: 121.452\n",
      "[40]\tvalid_0's l2: 120.318\n",
      "[41]\tvalid_0's l2: 119.221\n",
      "[42]\tvalid_0's l2: 118.181\n",
      "[43]\tvalid_0's l2: 117.128\n",
      "[44]\tvalid_0's l2: 116.164\n",
      "[45]\tvalid_0's l2: 115.21\n",
      "[46]\tvalid_0's l2: 114.195\n",
      "[47]\tvalid_0's l2: 113.257\n",
      "[48]\tvalid_0's l2: 112.308\n",
      "[49]\tvalid_0's l2: 111.421\n",
      "[50]\tvalid_0's l2: 110.55\n",
      "[51]\tvalid_0's l2: 109.619\n",
      "[52]\tvalid_0's l2: 108.785\n",
      "[53]\tvalid_0's l2: 107.915\n",
      "[54]\tvalid_0's l2: 107.033\n",
      "[55]\tvalid_0's l2: 106.2\n",
      "[56]\tvalid_0's l2: 105.414\n",
      "[57]\tvalid_0's l2: 104.617\n",
      "[58]\tvalid_0's l2: 103.798\n",
      "[59]\tvalid_0's l2: 103.079\n",
      "[60]\tvalid_0's l2: 102.311\n",
      "[61]\tvalid_0's l2: 101.624\n",
      "[62]\tvalid_0's l2: 100.912\n",
      "[63]\tvalid_0's l2: 100.164\n",
      "[64]\tvalid_0's l2: 99.434\n",
      "[65]\tvalid_0's l2: 98.7489\n",
      "[66]\tvalid_0's l2: 98.0793\n",
      "[67]\tvalid_0's l2: 97.4142\n",
      "[68]\tvalid_0's l2: 96.7814\n",
      "[69]\tvalid_0's l2: 96.1638\n",
      "[70]\tvalid_0's l2: 95.5322\n",
      "[71]\tvalid_0's l2: 94.9376\n",
      "[72]\tvalid_0's l2: 94.3122\n",
      "[73]\tvalid_0's l2: 93.6876\n",
      "[74]\tvalid_0's l2: 93.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75]\tvalid_0's l2: 92.5882\n",
      "[76]\tvalid_0's l2: 92.0526\n",
      "[77]\tvalid_0's l2: 91.4721\n",
      "[78]\tvalid_0's l2: 90.9443\n",
      "[79]\tvalid_0's l2: 90.4219\n",
      "[80]\tvalid_0's l2: 89.9142\n",
      "[81]\tvalid_0's l2: 89.4646\n",
      "[82]\tvalid_0's l2: 88.976\n",
      "[83]\tvalid_0's l2: 88.4994\n",
      "[84]\tvalid_0's l2: 88.0173\n",
      "[85]\tvalid_0's l2: 87.5609\n",
      "[86]\tvalid_0's l2: 87.1235\n",
      "[87]\tvalid_0's l2: 86.6915\n",
      "[88]\tvalid_0's l2: 86.2396\n",
      "[89]\tvalid_0's l2: 85.7769\n",
      "[90]\tvalid_0's l2: 85.4063\n",
      "[91]\tvalid_0's l2: 84.9977\n",
      "[92]\tvalid_0's l2: 84.5858\n",
      "[93]\tvalid_0's l2: 84.1924\n",
      "[94]\tvalid_0's l2: 83.7917\n",
      "[95]\tvalid_0's l2: 83.4248\n",
      "[96]\tvalid_0's l2: 83.0641\n",
      "[97]\tvalid_0's l2: 82.6946\n",
      "[98]\tvalid_0's l2: 82.2948\n",
      "[99]\tvalid_0's l2: 81.9032\n",
      "[100]\tvalid_0's l2: 81.5208\n",
      "[101]\tvalid_0's l2: 81.1816\n",
      "[102]\tvalid_0's l2: 80.8688\n",
      "[103]\tvalid_0's l2: 80.544\n",
      "[104]\tvalid_0's l2: 80.1865\n",
      "[105]\tvalid_0's l2: 79.8693\n",
      "[106]\tvalid_0's l2: 79.5273\n",
      "[107]\tvalid_0's l2: 79.1901\n",
      "[108]\tvalid_0's l2: 78.8537\n",
      "[109]\tvalid_0's l2: 78.5328\n",
      "[110]\tvalid_0's l2: 78.2151\n",
      "[111]\tvalid_0's l2: 77.9376\n",
      "[112]\tvalid_0's l2: 77.6402\n",
      "[113]\tvalid_0's l2: 77.3489\n",
      "[114]\tvalid_0's l2: 77.0851\n",
      "[115]\tvalid_0's l2: 76.8204\n",
      "[116]\tvalid_0's l2: 76.5357\n",
      "[117]\tvalid_0's l2: 76.2837\n",
      "[118]\tvalid_0's l2: 76.0256\n",
      "[119]\tvalid_0's l2: 75.7739\n",
      "[120]\tvalid_0's l2: 75.5071\n",
      "[121]\tvalid_0's l2: 75.2774\n",
      "[122]\tvalid_0's l2: 75.0489\n",
      "[123]\tvalid_0's l2: 74.8235\n",
      "[124]\tvalid_0's l2: 74.5849\n",
      "[125]\tvalid_0's l2: 74.3798\n",
      "[126]\tvalid_0's l2: 74.1394\n",
      "[127]\tvalid_0's l2: 73.934\n",
      "[128]\tvalid_0's l2: 73.7484\n",
      "[129]\tvalid_0's l2: 73.5306\n",
      "[130]\tvalid_0's l2: 73.3367\n",
      "[131]\tvalid_0's l2: 73.1072\n",
      "[132]\tvalid_0's l2: 72.9339\n",
      "[133]\tvalid_0's l2: 72.7303\n",
      "[134]\tvalid_0's l2: 72.549\n",
      "[135]\tvalid_0's l2: 72.3798\n",
      "[136]\tvalid_0's l2: 72.1886\n",
      "[137]\tvalid_0's l2: 72.0343\n",
      "[138]\tvalid_0's l2: 71.8882\n",
      "[139]\tvalid_0's l2: 71.7294\n",
      "[140]\tvalid_0's l2: 71.5455\n",
      "[141]\tvalid_0's l2: 71.4048\n",
      "[142]\tvalid_0's l2: 71.2191\n",
      "[143]\tvalid_0's l2: 71.0364\n",
      "[144]\tvalid_0's l2: 70.8805\n",
      "[145]\tvalid_0's l2: 70.7157\n",
      "[146]\tvalid_0's l2: 70.5557\n",
      "[147]\tvalid_0's l2: 70.43\n",
      "[148]\tvalid_0's l2: 70.2593\n",
      "[149]\tvalid_0's l2: 70.1004\n",
      "[150]\tvalid_0's l2: 69.9417\n",
      "[151]\tvalid_0's l2: 69.7995\n",
      "[152]\tvalid_0's l2: 69.6544\n",
      "[153]\tvalid_0's l2: 69.5343\n",
      "[154]\tvalid_0's l2: 69.3866\n",
      "[155]\tvalid_0's l2: 69.2411\n",
      "[156]\tvalid_0's l2: 69.0841\n",
      "[157]\tvalid_0's l2: 68.9739\n",
      "[158]\tvalid_0's l2: 68.8587\n",
      "[159]\tvalid_0's l2: 68.7232\n",
      "[160]\tvalid_0's l2: 68.5971\n",
      "[161]\tvalid_0's l2: 68.4551\n",
      "[162]\tvalid_0's l2: 68.3543\n",
      "[163]\tvalid_0's l2: 68.2442\n",
      "[164]\tvalid_0's l2: 68.1424\n",
      "[165]\tvalid_0's l2: 68.0024\n",
      "[166]\tvalid_0's l2: 67.9114\n",
      "[167]\tvalid_0's l2: 67.8023\n",
      "[168]\tvalid_0's l2: 67.669\n",
      "[169]\tvalid_0's l2: 67.5864\n",
      "[170]\tvalid_0's l2: 67.481\n",
      "[171]\tvalid_0's l2: 67.3873\n",
      "[172]\tvalid_0's l2: 67.2711\n",
      "[173]\tvalid_0's l2: 67.1653\n",
      "[174]\tvalid_0's l2: 67.0684\n",
      "[175]\tvalid_0's l2: 66.9689\n",
      "[176]\tvalid_0's l2: 66.8597\n",
      "[177]\tvalid_0's l2: 66.754\n",
      "[178]\tvalid_0's l2: 66.6657\n",
      "[179]\tvalid_0's l2: 66.5612\n",
      "[180]\tvalid_0's l2: 66.5116\n",
      "[181]\tvalid_0's l2: 66.394\n",
      "[182]\tvalid_0's l2: 66.3188\n",
      "[183]\tvalid_0's l2: 66.2219\n",
      "[184]\tvalid_0's l2: 66.1326\n",
      "[185]\tvalid_0's l2: 66.0244\n",
      "[186]\tvalid_0's l2: 65.9638\n",
      "[187]\tvalid_0's l2: 65.8736\n",
      "[188]\tvalid_0's l2: 65.8128\n",
      "[189]\tvalid_0's l2: 65.7232\n",
      "[190]\tvalid_0's l2: 65.6654\n",
      "[191]\tvalid_0's l2: 65.5949\n",
      "[192]\tvalid_0's l2: 65.5131\n",
      "[193]\tvalid_0's l2: 65.4204\n",
      "[194]\tvalid_0's l2: 65.3748\n",
      "[195]\tvalid_0's l2: 65.2973\n",
      "[196]\tvalid_0's l2: 65.2797\n",
      "[197]\tvalid_0's l2: 65.2264\n",
      "[198]\tvalid_0's l2: 65.1941\n",
      "[199]\tvalid_0's l2: 65.1082\n",
      "[200]\tvalid_0's l2: 65.091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 65.091\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 4 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.626\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 206.347\n",
      "[3]\tvalid_0's l2: 203.028\n",
      "[4]\tvalid_0's l2: 199.763\n",
      "[5]\tvalid_0's l2: 196.688\n",
      "[6]\tvalid_0's l2: 193.583\n",
      "[7]\tvalid_0's l2: 190.557\n",
      "[8]\tvalid_0's l2: 187.665\n",
      "[9]\tvalid_0's l2: 184.76\n",
      "[10]\tvalid_0's l2: 181.903\n",
      "[11]\tvalid_0's l2: 179.111\n",
      "[12]\tvalid_0's l2: 176.348\n",
      "[13]\tvalid_0's l2: 173.667\n",
      "[14]\tvalid_0's l2: 171.105\n",
      "[15]\tvalid_0's l2: 168.497\n",
      "[16]\tvalid_0's l2: 165.996\n",
      "[17]\tvalid_0's l2: 163.529\n",
      "[18]\tvalid_0's l2: 161.091\n",
      "[19]\tvalid_0's l2: 158.714\n",
      "[20]\tvalid_0's l2: 156.422\n",
      "[21]\tvalid_0's l2: 154.165\n",
      "[22]\tvalid_0's l2: 151.991\n",
      "[23]\tvalid_0's l2: 149.79\n",
      "[24]\tvalid_0's l2: 147.715\n",
      "[25]\tvalid_0's l2: 145.611\n",
      "[26]\tvalid_0's l2: 143.559\n",
      "[27]\tvalid_0's l2: 141.575\n",
      "[28]\tvalid_0's l2: 139.605\n",
      "[29]\tvalid_0's l2: 137.673\n",
      "[30]\tvalid_0's l2: 135.823\n",
      "[31]\tvalid_0's l2: 134.005\n",
      "[32]\tvalid_0's l2: 132.188\n",
      "[33]\tvalid_0's l2: 130.42\n",
      "[34]\tvalid_0's l2: 128.716\n",
      "[35]\tvalid_0's l2: 127.052\n",
      "[36]\tvalid_0's l2: 125.419\n",
      "[37]\tvalid_0's l2: 123.782\n",
      "[38]\tvalid_0's l2: 122.18\n",
      "[39]\tvalid_0's l2: 120.653\n",
      "[40]\tvalid_0's l2: 119.155\n",
      "[41]\tvalid_0's l2: 117.686\n",
      "[42]\tvalid_0's l2: 116.222\n",
      "[43]\tvalid_0's l2: 114.779\n",
      "[44]\tvalid_0's l2: 113.397\n",
      "[45]\tvalid_0's l2: 112.026\n",
      "[46]\tvalid_0's l2: 110.692\n",
      "[47]\tvalid_0's l2: 109.415\n",
      "[48]\tvalid_0's l2: 108.121\n",
      "[49]\tvalid_0's l2: 106.906\n",
      "[50]\tvalid_0's l2: 105.69\n",
      "[51]\tvalid_0's l2: 104.505\n",
      "[52]\tvalid_0's l2: 103.346\n",
      "[53]\tvalid_0's l2: 102.207\n",
      "[54]\tvalid_0's l2: 101.096\n",
      "[55]\tvalid_0's l2: 100.016\n",
      "[56]\tvalid_0's l2: 98.9512\n",
      "[57]\tvalid_0's l2: 97.8867\n",
      "[58]\tvalid_0's l2: 96.8655\n",
      "[59]\tvalid_0's l2: 95.8822\n",
      "[60]\tvalid_0's l2: 94.9045\n",
      "[61]\tvalid_0's l2: 93.935\n",
      "[62]\tvalid_0's l2: 93.0383\n",
      "[63]\tvalid_0's l2: 92.1226\n",
      "[64]\tvalid_0's l2: 91.2246\n",
      "[65]\tvalid_0's l2: 90.387\n",
      "[66]\tvalid_0's l2: 89.5251\n",
      "[67]\tvalid_0's l2: 88.6695\n",
      "[68]\tvalid_0's l2: 87.8557\n",
      "[69]\tvalid_0's l2: 87.0612\n",
      "[70]\tvalid_0's l2: 86.3036\n",
      "[71]\tvalid_0's l2: 85.5517\n",
      "[72]\tvalid_0's l2: 84.7985\n",
      "[73]\tvalid_0's l2: 84.0945\n",
      "[74]\tvalid_0's l2: 83.4088\n",
      "[75]\tvalid_0's l2: 82.7059\n",
      "[76]\tvalid_0's l2: 82.0263\n",
      "[77]\tvalid_0's l2: 81.3512\n",
      "[78]\tvalid_0's l2: 80.7109\n",
      "[79]\tvalid_0's l2: 80.1005\n",
      "[80]\tvalid_0's l2: 79.4996\n",
      "[81]\tvalid_0's l2: 78.9146\n",
      "[82]\tvalid_0's l2: 78.3446\n",
      "[83]\tvalid_0's l2: 77.7455\n",
      "[84]\tvalid_0's l2: 77.1827\n",
      "[85]\tvalid_0's l2: 76.6563\n",
      "[86]\tvalid_0's l2: 76.1072\n",
      "[87]\tvalid_0's l2: 75.6043\n",
      "[88]\tvalid_0's l2: 75.0928\n",
      "[89]\tvalid_0's l2: 74.5759\n",
      "[90]\tvalid_0's l2: 74.1186\n",
      "[91]\tvalid_0's l2: 73.661\n",
      "[92]\tvalid_0's l2: 73.1847\n",
      "[93]\tvalid_0's l2: 72.7241\n",
      "[94]\tvalid_0's l2: 72.268\n",
      "[95]\tvalid_0's l2: 71.8568\n",
      "[96]\tvalid_0's l2: 71.4381\n",
      "[97]\tvalid_0's l2: 71.0186\n",
      "[98]\tvalid_0's l2: 70.5939\n",
      "[99]\tvalid_0's l2: 70.1797\n",
      "[100]\tvalid_0's l2: 69.7766\n",
      "[101]\tvalid_0's l2: 69.4226\n",
      "[102]\tvalid_0's l2: 69.0602\n",
      "[103]\tvalid_0's l2: 68.6994\n",
      "[104]\tvalid_0's l2: 68.3259\n",
      "[105]\tvalid_0's l2: 67.9731\n",
      "[106]\tvalid_0's l2: 67.6166\n",
      "[107]\tvalid_0's l2: 67.2635\n",
      "[108]\tvalid_0's l2: 66.9227\n",
      "[109]\tvalid_0's l2: 66.593\n",
      "[110]\tvalid_0's l2: 66.2679\n",
      "[111]\tvalid_0's l2: 65.988\n",
      "[112]\tvalid_0's l2: 65.7104\n",
      "[113]\tvalid_0's l2: 65.4059\n",
      "[114]\tvalid_0's l2: 65.1391\n",
      "[115]\tvalid_0's l2: 64.8586\n",
      "[116]\tvalid_0's l2: 64.5933\n",
      "[117]\tvalid_0's l2: 64.3295\n",
      "[118]\tvalid_0's l2: 64.0766\n",
      "[119]\tvalid_0's l2: 63.8221\n",
      "[120]\tvalid_0's l2: 63.5769\n",
      "[121]\tvalid_0's l2: 63.3426\n",
      "[122]\tvalid_0's l2: 63.1101\n",
      "[123]\tvalid_0's l2: 62.8905\n",
      "[124]\tvalid_0's l2: 62.6806\n",
      "[125]\tvalid_0's l2: 62.4759\n",
      "[126]\tvalid_0's l2: 62.2675\n",
      "[127]\tvalid_0's l2: 62.066\n",
      "[128]\tvalid_0's l2: 61.9035\n",
      "[129]\tvalid_0's l2: 61.6968\n",
      "[130]\tvalid_0's l2: 61.5163\n",
      "[131]\tvalid_0's l2: 61.32\n",
      "[132]\tvalid_0's l2: 61.1495\n",
      "[133]\tvalid_0's l2: 60.9771\n",
      "[134]\tvalid_0's l2: 60.841\n",
      "[135]\tvalid_0's l2: 60.7113\n",
      "[136]\tvalid_0's l2: 60.5371\n",
      "[137]\tvalid_0's l2: 60.3827\n",
      "[138]\tvalid_0's l2: 60.2329\n",
      "[139]\tvalid_0's l2: 60.1123\n",
      "[140]\tvalid_0's l2: 60.0034\n",
      "[141]\tvalid_0's l2: 59.8654\n",
      "[142]\tvalid_0's l2: 59.7143\n",
      "[143]\tvalid_0's l2: 59.5678\n",
      "[144]\tvalid_0's l2: 59.4409\n",
      "[145]\tvalid_0's l2: 59.302\n",
      "[146]\tvalid_0's l2: 59.1675\n",
      "[147]\tvalid_0's l2: 59.0786\n",
      "[148]\tvalid_0's l2: 58.9618\n",
      "[149]\tvalid_0's l2: 58.8581\n",
      "[150]\tvalid_0's l2: 58.7544\n",
      "[151]\tvalid_0's l2: 58.6601\n",
      "[152]\tvalid_0's l2: 58.5449\n",
      "[153]\tvalid_0's l2: 58.4489\n",
      "[154]\tvalid_0's l2: 58.3613\n",
      "[155]\tvalid_0's l2: 58.2686\n",
      "[156]\tvalid_0's l2: 58.1905\n",
      "[157]\tvalid_0's l2: 58.1109\n",
      "[158]\tvalid_0's l2: 58.0329\n",
      "[159]\tvalid_0's l2: 57.937\n",
      "[160]\tvalid_0's l2: 57.8753\n",
      "[161]\tvalid_0's l2: 57.8065\n",
      "[162]\tvalid_0's l2: 57.7538\n",
      "[163]\tvalid_0's l2: 57.6904\n",
      "[164]\tvalid_0's l2: 57.6376\n",
      "[165]\tvalid_0's l2: 57.6051\n",
      "[166]\tvalid_0's l2: 57.5502\n",
      "[167]\tvalid_0's l2: 57.4777\n",
      "[168]\tvalid_0's l2: 57.4318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169]\tvalid_0's l2: 57.3879\n",
      "[170]\tvalid_0's l2: 57.3303\n",
      "[171]\tvalid_0's l2: 57.2939\n",
      "[172]\tvalid_0's l2: 57.2731\n",
      "[173]\tvalid_0's l2: 57.2118\n",
      "[174]\tvalid_0's l2: 57.1734\n",
      "[175]\tvalid_0's l2: 57.1295\n",
      "[176]\tvalid_0's l2: 57.0738\n",
      "[177]\tvalid_0's l2: 57.04\n",
      "[178]\tvalid_0's l2: 57.012\n",
      "[179]\tvalid_0's l2: 56.9985\n",
      "[180]\tvalid_0's l2: 56.9923\n",
      "[181]\tvalid_0's l2: 56.9818\n",
      "[182]\tvalid_0's l2: 56.9603\n",
      "[183]\tvalid_0's l2: 56.9611\n",
      "[184]\tvalid_0's l2: 56.9175\n",
      "[185]\tvalid_0's l2: 56.9128\n",
      "[186]\tvalid_0's l2: 56.8818\n",
      "[187]\tvalid_0's l2: 56.8895\n",
      "[188]\tvalid_0's l2: 56.879\n",
      "[189]\tvalid_0's l2: 56.8651\n",
      "[190]\tvalid_0's l2: 56.8509\n",
      "[191]\tvalid_0's l2: 56.818\n",
      "[192]\tvalid_0's l2: 56.8124\n",
      "[193]\tvalid_0's l2: 56.8255\n",
      "[194]\tvalid_0's l2: 56.8026\n",
      "[195]\tvalid_0's l2: 56.7938\n",
      "[196]\tvalid_0's l2: 56.8004\n",
      "[197]\tvalid_0's l2: 56.7999\n",
      "[198]\tvalid_0's l2: 56.7903\n",
      "[199]\tvalid_0's l2: 56.8063\n",
      "[200]\tvalid_0's l2: 56.8154\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[198]\tvalid_0's l2: 56.7903\n",
      "Training Iteration:  198\n",
      "Train:\tValid:\t***** Depth:  7  *****\n",
      "Fold 0 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.528\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 207.458\n",
      "[3]\tvalid_0's l2: 205.33\n",
      "[4]\tvalid_0's l2: 203.223\n",
      "[5]\tvalid_0's l2: 201.299\n",
      "[6]\tvalid_0's l2: 199.335\n",
      "[7]\tvalid_0's l2: 197.386\n",
      "[8]\tvalid_0's l2: 195.615\n",
      "[9]\tvalid_0's l2: 193.768\n",
      "[10]\tvalid_0's l2: 192.008\n",
      "[11]\tvalid_0's l2: 190.305\n",
      "[12]\tvalid_0's l2: 188.622\n",
      "[13]\tvalid_0's l2: 186.936\n",
      "[14]\tvalid_0's l2: 185.435\n",
      "[15]\tvalid_0's l2: 183.837\n",
      "[16]\tvalid_0's l2: 182.341\n",
      "[17]\tvalid_0's l2: 180.809\n",
      "[18]\tvalid_0's l2: 179.385\n",
      "[19]\tvalid_0's l2: 177.974\n",
      "[20]\tvalid_0's l2: 176.58\n",
      "[21]\tvalid_0's l2: 175.252\n",
      "[22]\tvalid_0's l2: 174.045\n",
      "[23]\tvalid_0's l2: 172.728\n",
      "[24]\tvalid_0's l2: 171.586\n",
      "[25]\tvalid_0's l2: 170.386\n",
      "[26]\tvalid_0's l2: 169.216\n",
      "[27]\tvalid_0's l2: 168.105\n",
      "[28]\tvalid_0's l2: 167.041\n",
      "[29]\tvalid_0's l2: 166.03\n",
      "[30]\tvalid_0's l2: 165.071\n",
      "[31]\tvalid_0's l2: 164.055\n",
      "[32]\tvalid_0's l2: 163.103\n",
      "[33]\tvalid_0's l2: 162.187\n",
      "[34]\tvalid_0's l2: 161.284\n",
      "[35]\tvalid_0's l2: 160.476\n",
      "[36]\tvalid_0's l2: 159.682\n",
      "[37]\tvalid_0's l2: 158.957\n",
      "[38]\tvalid_0's l2: 158.184\n",
      "[39]\tvalid_0's l2: 157.447\n",
      "[40]\tvalid_0's l2: 156.717\n",
      "[41]\tvalid_0's l2: 156.024\n",
      "[42]\tvalid_0's l2: 155.368\n",
      "[43]\tvalid_0's l2: 154.657\n",
      "[44]\tvalid_0's l2: 154.027\n",
      "[45]\tvalid_0's l2: 153.394\n",
      "[46]\tvalid_0's l2: 152.787\n",
      "[47]\tvalid_0's l2: 152.204\n",
      "[48]\tvalid_0's l2: 151.62\n",
      "[49]\tvalid_0's l2: 151.066\n",
      "[50]\tvalid_0's l2: 150.543\n",
      "[51]\tvalid_0's l2: 150.047\n",
      "[52]\tvalid_0's l2: 149.541\n",
      "[53]\tvalid_0's l2: 149.085\n",
      "[54]\tvalid_0's l2: 148.621\n",
      "[55]\tvalid_0's l2: 148.192\n",
      "[56]\tvalid_0's l2: 147.815\n",
      "[57]\tvalid_0's l2: 147.44\n",
      "[58]\tvalid_0's l2: 147.05\n",
      "[59]\tvalid_0's l2: 146.657\n",
      "[60]\tvalid_0's l2: 146.295\n",
      "[61]\tvalid_0's l2: 145.981\n",
      "[62]\tvalid_0's l2: 145.66\n",
      "[63]\tvalid_0's l2: 145.345\n",
      "[64]\tvalid_0's l2: 145.037\n",
      "[65]\tvalid_0's l2: 144.774\n",
      "[66]\tvalid_0's l2: 144.481\n",
      "[67]\tvalid_0's l2: 144.199\n",
      "[68]\tvalid_0's l2: 143.933\n",
      "[69]\tvalid_0's l2: 143.705\n",
      "[70]\tvalid_0's l2: 143.475\n",
      "[71]\tvalid_0's l2: 143.257\n",
      "[72]\tvalid_0's l2: 143.049\n",
      "[73]\tvalid_0's l2: 142.844\n",
      "[74]\tvalid_0's l2: 142.655\n",
      "[75]\tvalid_0's l2: 142.473\n",
      "[76]\tvalid_0's l2: 142.3\n",
      "[77]\tvalid_0's l2: 142.14\n",
      "[78]\tvalid_0's l2: 141.992\n",
      "[79]\tvalid_0's l2: 141.857\n",
      "[80]\tvalid_0's l2: 141.693\n",
      "[81]\tvalid_0's l2: 141.575\n",
      "[82]\tvalid_0's l2: 141.451\n",
      "[83]\tvalid_0's l2: 141.369\n",
      "[84]\tvalid_0's l2: 141.268\n",
      "[85]\tvalid_0's l2: 141.198\n",
      "[86]\tvalid_0's l2: 141.123\n",
      "[87]\tvalid_0's l2: 141.025\n",
      "[88]\tvalid_0's l2: 140.968\n",
      "[89]\tvalid_0's l2: 140.874\n",
      "[90]\tvalid_0's l2: 140.835\n",
      "[91]\tvalid_0's l2: 140.8\n",
      "[92]\tvalid_0's l2: 140.734\n",
      "[93]\tvalid_0's l2: 140.673\n",
      "[94]\tvalid_0's l2: 140.614\n",
      "[95]\tvalid_0's l2: 140.567\n",
      "[96]\tvalid_0's l2: 140.567\n",
      "[97]\tvalid_0's l2: 140.572\n",
      "[98]\tvalid_0's l2: 140.536\n",
      "[99]\tvalid_0's l2: 140.52\n",
      "[100]\tvalid_0's l2: 140.465\n",
      "[101]\tvalid_0's l2: 140.485\n",
      "[102]\tvalid_0's l2: 140.468\n",
      "[103]\tvalid_0's l2: 140.496\n",
      "[104]\tvalid_0's l2: 140.509\n",
      "[105]\tvalid_0's l2: 140.547\n",
      "[106]\tvalid_0's l2: 140.544\n",
      "[107]\tvalid_0's l2: 140.563\n",
      "[108]\tvalid_0's l2: 140.579\n",
      "[109]\tvalid_0's l2: 140.596\n",
      "[110]\tvalid_0's l2: 140.584\n",
      "[111]\tvalid_0's l2: 140.635\n",
      "[112]\tvalid_0's l2: 140.691\n",
      "[113]\tvalid_0's l2: 140.694\n",
      "[114]\tvalid_0's l2: 140.758\n",
      "[115]\tvalid_0's l2: 140.832\n",
      "[116]\tvalid_0's l2: 140.947\n",
      "[117]\tvalid_0's l2: 141.017\n",
      "[118]\tvalid_0's l2: 141.093\n",
      "[119]\tvalid_0's l2: 141.161\n",
      "[120]\tvalid_0's l2: 141.249\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's l2: 140.465\n",
      "Training Iteration:  100\n",
      "Train:\tValid:\tFold 1 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.385\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 207.306\n",
      "[3]\tvalid_0's l2: 205.002\n",
      "[4]\tvalid_0's l2: 202.747\n",
      "[5]\tvalid_0's l2: 200.796\n",
      "[6]\tvalid_0's l2: 198.642\n",
      "[7]\tvalid_0's l2: 196.528\n",
      "[8]\tvalid_0's l2: 194.703\n",
      "[9]\tvalid_0's l2: 192.677\n",
      "[10]\tvalid_0's l2: 190.703\n",
      "[11]\tvalid_0's l2: 188.77\n",
      "[12]\tvalid_0's l2: 186.893\n",
      "[13]\tvalid_0's l2: 185.057\n",
      "[14]\tvalid_0's l2: 183.457\n",
      "[15]\tvalid_0's l2: 181.7\n",
      "[16]\tvalid_0's l2: 179.984\n",
      "[17]\tvalid_0's l2: 178.292\n",
      "[18]\tvalid_0's l2: 176.644\n",
      "[19]\tvalid_0's l2: 175.029\n",
      "[20]\tvalid_0's l2: 173.449\n",
      "[21]\tvalid_0's l2: 171.904\n",
      "[22]\tvalid_0's l2: 170.555\n",
      "[23]\tvalid_0's l2: 169.095\n",
      "[24]\tvalid_0's l2: 167.806\n",
      "[25]\tvalid_0's l2: 166.402\n",
      "[26]\tvalid_0's l2: 165.038\n",
      "[27]\tvalid_0's l2: 163.67\n",
      "[28]\tvalid_0's l2: 162.352\n",
      "[29]\tvalid_0's l2: 161.056\n",
      "[30]\tvalid_0's l2: 159.777\n",
      "[31]\tvalid_0's l2: 158.556\n",
      "[32]\tvalid_0's l2: 157.34\n",
      "[33]\tvalid_0's l2: 156.149\n",
      "[34]\tvalid_0's l2: 155.011\n",
      "[35]\tvalid_0's l2: 154.007\n",
      "[36]\tvalid_0's l2: 153.02\n",
      "[37]\tvalid_0's l2: 151.926\n",
      "[38]\tvalid_0's l2: 150.884\n",
      "[39]\tvalid_0's l2: 149.966\n",
      "[40]\tvalid_0's l2: 148.968\n",
      "[41]\tvalid_0's l2: 148.083\n",
      "[42]\tvalid_0's l2: 147.118\n",
      "[43]\tvalid_0's l2: 146.144\n",
      "[44]\tvalid_0's l2: 145.212\n",
      "[45]\tvalid_0's l2: 144.269\n",
      "[46]\tvalid_0's l2: 143.387\n",
      "[47]\tvalid_0's l2: 142.556\n",
      "[48]\tvalid_0's l2: 141.712\n",
      "[49]\tvalid_0's l2: 140.909\n",
      "[50]\tvalid_0's l2: 140.054\n",
      "[51]\tvalid_0's l2: 139.349\n",
      "[52]\tvalid_0's l2: 138.546\n",
      "[53]\tvalid_0's l2: 137.789\n",
      "[54]\tvalid_0's l2: 137.131\n",
      "[55]\tvalid_0's l2: 136.419\n",
      "[56]\tvalid_0's l2: 135.671\n",
      "[57]\tvalid_0's l2: 134.969\n",
      "[58]\tvalid_0's l2: 134.369\n",
      "[59]\tvalid_0's l2: 133.727\n",
      "[60]\tvalid_0's l2: 133.163\n",
      "[61]\tvalid_0's l2: 132.538\n",
      "[62]\tvalid_0's l2: 131.912\n",
      "[63]\tvalid_0's l2: 131.388\n",
      "[64]\tvalid_0's l2: 130.866\n",
      "[65]\tvalid_0's l2: 130.265\n",
      "[66]\tvalid_0's l2: 129.715\n",
      "[67]\tvalid_0's l2: 129.157\n",
      "[68]\tvalid_0's l2: 128.62\n",
      "[69]\tvalid_0's l2: 128.109\n",
      "[70]\tvalid_0's l2: 127.612\n",
      "[71]\tvalid_0's l2: 127.089\n",
      "[72]\tvalid_0's l2: 126.657\n",
      "[73]\tvalid_0's l2: 126.163\n",
      "[74]\tvalid_0's l2: 125.734\n",
      "[75]\tvalid_0's l2: 125.244\n",
      "[76]\tvalid_0's l2: 124.794\n",
      "[77]\tvalid_0's l2: 124.413\n",
      "[78]\tvalid_0's l2: 124.012\n",
      "[79]\tvalid_0's l2: 123.577\n",
      "[80]\tvalid_0's l2: 123.157\n",
      "[81]\tvalid_0's l2: 122.748\n",
      "[82]\tvalid_0's l2: 122.397\n",
      "[83]\tvalid_0's l2: 121.979\n",
      "[84]\tvalid_0's l2: 121.63\n",
      "[85]\tvalid_0's l2: 121.259\n",
      "[86]\tvalid_0's l2: 120.926\n",
      "[87]\tvalid_0's l2: 120.584\n",
      "[88]\tvalid_0's l2: 120.254\n",
      "[89]\tvalid_0's l2: 119.978\n",
      "[90]\tvalid_0's l2: 119.687\n",
      "[91]\tvalid_0's l2: 119.404\n",
      "[92]\tvalid_0's l2: 119.117\n",
      "[93]\tvalid_0's l2: 118.82\n",
      "[94]\tvalid_0's l2: 118.559\n",
      "[95]\tvalid_0's l2: 118.272\n",
      "[96]\tvalid_0's l2: 118.032\n",
      "[97]\tvalid_0's l2: 117.78\n",
      "[98]\tvalid_0's l2: 117.548\n",
      "[99]\tvalid_0's l2: 117.324\n",
      "[100]\tvalid_0's l2: 117.109\n",
      "[101]\tvalid_0's l2: 116.88\n",
      "[102]\tvalid_0's l2: 116.66\n",
      "[103]\tvalid_0's l2: 116.428\n",
      "[104]\tvalid_0's l2: 116.237\n",
      "[105]\tvalid_0's l2: 116.036\n",
      "[106]\tvalid_0's l2: 115.856\n",
      "[107]\tvalid_0's l2: 115.681\n",
      "[108]\tvalid_0's l2: 115.51\n",
      "[109]\tvalid_0's l2: 115.335\n",
      "[110]\tvalid_0's l2: 115.166\n",
      "[111]\tvalid_0's l2: 114.988\n",
      "[112]\tvalid_0's l2: 114.811\n",
      "[113]\tvalid_0's l2: 114.67\n",
      "[114]\tvalid_0's l2: 114.408\n",
      "[115]\tvalid_0's l2: 114.265\n",
      "[116]\tvalid_0's l2: 114.022\n",
      "[117]\tvalid_0's l2: 113.796\n",
      "[118]\tvalid_0's l2: 113.572\n",
      "[119]\tvalid_0's l2: 113.35\n",
      "[120]\tvalid_0's l2: 113.229\n",
      "[121]\tvalid_0's l2: 113.049\n",
      "[122]\tvalid_0's l2: 112.847\n",
      "[123]\tvalid_0's l2: 112.659\n",
      "[124]\tvalid_0's l2: 112.463\n",
      "[125]\tvalid_0's l2: 112.275\n",
      "[126]\tvalid_0's l2: 112.11\n",
      "[127]\tvalid_0's l2: 111.977\n",
      "[128]\tvalid_0's l2: 111.801\n",
      "[129]\tvalid_0's l2: 111.708\n",
      "[130]\tvalid_0's l2: 111.546\n",
      "[131]\tvalid_0's l2: 111.461\n",
      "[132]\tvalid_0's l2: 111.33\n",
      "[133]\tvalid_0's l2: 111.212\n",
      "[134]\tvalid_0's l2: 111.06\n",
      "[135]\tvalid_0's l2: 110.898\n",
      "[136]\tvalid_0's l2: 110.831\n",
      "[137]\tvalid_0's l2: 110.694\n",
      "[138]\tvalid_0's l2: 110.543\n",
      "[139]\tvalid_0's l2: 110.449\n",
      "[140]\tvalid_0's l2: 110.322\n",
      "[141]\tvalid_0's l2: 110.183\n",
      "[142]\tvalid_0's l2: 110.109\n",
      "[143]\tvalid_0's l2: 110.037\n",
      "[144]\tvalid_0's l2: 109.935\n",
      "[145]\tvalid_0's l2: 109.865\n",
      "[146]\tvalid_0's l2: 109.798\n",
      "[147]\tvalid_0's l2: 109.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148]\tvalid_0's l2: 109.605\n",
      "[149]\tvalid_0's l2: 109.511\n",
      "[150]\tvalid_0's l2: 109.372\n",
      "[151]\tvalid_0's l2: 109.283\n",
      "[152]\tvalid_0's l2: 109.237\n",
      "[153]\tvalid_0's l2: 109.142\n",
      "[154]\tvalid_0's l2: 109.012\n",
      "[155]\tvalid_0's l2: 108.937\n",
      "[156]\tvalid_0's l2: 108.856\n",
      "[157]\tvalid_0's l2: 108.801\n",
      "[158]\tvalid_0's l2: 108.693\n",
      "[159]\tvalid_0's l2: 108.651\n",
      "[160]\tvalid_0's l2: 108.569\n",
      "[161]\tvalid_0's l2: 108.463\n",
      "[162]\tvalid_0's l2: 108.384\n",
      "[163]\tvalid_0's l2: 108.297\n",
      "[164]\tvalid_0's l2: 108.207\n",
      "[165]\tvalid_0's l2: 108.138\n",
      "[166]\tvalid_0's l2: 108.078\n",
      "[167]\tvalid_0's l2: 108.046\n",
      "[168]\tvalid_0's l2: 107.968\n",
      "[169]\tvalid_0's l2: 107.897\n",
      "[170]\tvalid_0's l2: 107.865\n",
      "[171]\tvalid_0's l2: 107.84\n",
      "[172]\tvalid_0's l2: 107.772\n",
      "[173]\tvalid_0's l2: 107.742\n",
      "[174]\tvalid_0's l2: 107.647\n",
      "[175]\tvalid_0's l2: 107.603\n",
      "[176]\tvalid_0's l2: 107.587\n",
      "[177]\tvalid_0's l2: 107.553\n",
      "[178]\tvalid_0's l2: 107.493\n",
      "[179]\tvalid_0's l2: 107.443\n",
      "[180]\tvalid_0's l2: 107.427\n",
      "[181]\tvalid_0's l2: 107.366\n",
      "[182]\tvalid_0's l2: 107.356\n",
      "[183]\tvalid_0's l2: 107.32\n",
      "[184]\tvalid_0's l2: 107.303\n",
      "[185]\tvalid_0's l2: 107.255\n",
      "[186]\tvalid_0's l2: 107.25\n",
      "[187]\tvalid_0's l2: 107.195\n",
      "[188]\tvalid_0's l2: 107.187\n",
      "[189]\tvalid_0's l2: 107.182\n",
      "[190]\tvalid_0's l2: 107.123\n",
      "[191]\tvalid_0's l2: 107.118\n",
      "[192]\tvalid_0's l2: 107.118\n",
      "[193]\tvalid_0's l2: 107.074\n",
      "[194]\tvalid_0's l2: 107.075\n",
      "[195]\tvalid_0's l2: 107.077\n",
      "[196]\tvalid_0's l2: 107.004\n",
      "[197]\tvalid_0's l2: 107.009\n",
      "[198]\tvalid_0's l2: 106.999\n",
      "[199]\tvalid_0's l2: 106.985\n",
      "[200]\tvalid_0's l2: 106.95\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 106.95\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 2 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 173.687\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 171.851\n",
      "[3]\tvalid_0's l2: 169.771\n",
      "[4]\tvalid_0's l2: 167.734\n",
      "[5]\tvalid_0's l2: 166.008\n",
      "[6]\tvalid_0's l2: 164.02\n",
      "[7]\tvalid_0's l2: 162.101\n",
      "[8]\tvalid_0's l2: 160.483\n",
      "[9]\tvalid_0's l2: 158.614\n",
      "[10]\tvalid_0's l2: 156.809\n",
      "[11]\tvalid_0's l2: 155.024\n",
      "[12]\tvalid_0's l2: 153.275\n",
      "[13]\tvalid_0's l2: 151.562\n",
      "[14]\tvalid_0's l2: 150.127\n",
      "[15]\tvalid_0's l2: 148.465\n",
      "[16]\tvalid_0's l2: 146.847\n",
      "[17]\tvalid_0's l2: 145.259\n",
      "[18]\tvalid_0's l2: 143.747\n",
      "[19]\tvalid_0's l2: 142.226\n",
      "[20]\tvalid_0's l2: 140.724\n",
      "[21]\tvalid_0's l2: 139.271\n",
      "[22]\tvalid_0's l2: 138.055\n",
      "[23]\tvalid_0's l2: 136.704\n",
      "[24]\tvalid_0's l2: 135.532\n",
      "[25]\tvalid_0's l2: 134.172\n",
      "[26]\tvalid_0's l2: 132.836\n",
      "[27]\tvalid_0's l2: 131.562\n",
      "[28]\tvalid_0's l2: 130.303\n",
      "[29]\tvalid_0's l2: 129.101\n",
      "[30]\tvalid_0's l2: 127.916\n",
      "[31]\tvalid_0's l2: 126.719\n",
      "[32]\tvalid_0's l2: 125.575\n",
      "[33]\tvalid_0's l2: 124.409\n",
      "[34]\tvalid_0's l2: 123.28\n",
      "[35]\tvalid_0's l2: 122.346\n",
      "[36]\tvalid_0's l2: 121.432\n",
      "[37]\tvalid_0's l2: 120.397\n",
      "[38]\tvalid_0's l2: 119.327\n",
      "[39]\tvalid_0's l2: 118.467\n",
      "[40]\tvalid_0's l2: 117.476\n",
      "[41]\tvalid_0's l2: 116.65\n",
      "[42]\tvalid_0's l2: 115.719\n",
      "[43]\tvalid_0's l2: 114.799\n",
      "[44]\tvalid_0's l2: 113.855\n",
      "[45]\tvalid_0's l2: 112.951\n",
      "[46]\tvalid_0's l2: 112.109\n",
      "[47]\tvalid_0's l2: 111.207\n",
      "[48]\tvalid_0's l2: 110.347\n",
      "[49]\tvalid_0's l2: 109.516\n",
      "[50]\tvalid_0's l2: 108.711\n",
      "[51]\tvalid_0's l2: 108.038\n",
      "[52]\tvalid_0's l2: 107.283\n",
      "[53]\tvalid_0's l2: 106.514\n",
      "[54]\tvalid_0's l2: 105.885\n",
      "[55]\tvalid_0's l2: 105.167\n",
      "[56]\tvalid_0's l2: 104.471\n",
      "[57]\tvalid_0's l2: 103.743\n",
      "[58]\tvalid_0's l2: 103.163\n",
      "[59]\tvalid_0's l2: 102.486\n",
      "[60]\tvalid_0's l2: 101.933\n",
      "[61]\tvalid_0's l2: 101.301\n",
      "[62]\tvalid_0's l2: 100.704\n",
      "[63]\tvalid_0's l2: 100.182\n",
      "[64]\tvalid_0's l2: 99.6657\n",
      "[65]\tvalid_0's l2: 99.0626\n",
      "[66]\tvalid_0's l2: 98.4876\n",
      "[67]\tvalid_0's l2: 97.8807\n",
      "[68]\tvalid_0's l2: 97.3041\n",
      "[69]\tvalid_0's l2: 96.7283\n",
      "[70]\tvalid_0's l2: 96.1749\n",
      "[71]\tvalid_0's l2: 95.6683\n",
      "[72]\tvalid_0's l2: 95.2293\n",
      "[73]\tvalid_0's l2: 94.6808\n",
      "[74]\tvalid_0's l2: 94.1824\n",
      "[75]\tvalid_0's l2: 93.7091\n",
      "[76]\tvalid_0's l2: 93.2181\n",
      "[77]\tvalid_0's l2: 92.8283\n",
      "[78]\tvalid_0's l2: 92.3559\n",
      "[79]\tvalid_0's l2: 91.9109\n",
      "[80]\tvalid_0's l2: 91.4767\n",
      "[81]\tvalid_0's l2: 91.0534\n",
      "[82]\tvalid_0's l2: 90.6557\n",
      "[83]\tvalid_0's l2: 90.2191\n",
      "[84]\tvalid_0's l2: 89.8063\n",
      "[85]\tvalid_0's l2: 89.3714\n",
      "[86]\tvalid_0's l2: 88.9866\n",
      "[87]\tvalid_0's l2: 88.6146\n",
      "[88]\tvalid_0's l2: 88.2678\n",
      "[89]\tvalid_0's l2: 87.9658\n",
      "[90]\tvalid_0's l2: 87.5864\n",
      "[91]\tvalid_0's l2: 87.2433\n",
      "[92]\tvalid_0's l2: 86.8702\n",
      "[93]\tvalid_0's l2: 86.5427\n",
      "[94]\tvalid_0's l2: 86.2066\n",
      "[95]\tvalid_0's l2: 85.883\n",
      "[96]\tvalid_0's l2: 85.5617\n",
      "[97]\tvalid_0's l2: 85.2376\n",
      "[98]\tvalid_0's l2: 84.9845\n",
      "[99]\tvalid_0's l2: 84.7399\n",
      "[100]\tvalid_0's l2: 84.5027\n",
      "[101]\tvalid_0's l2: 84.1616\n",
      "[102]\tvalid_0's l2: 83.8456\n",
      "[103]\tvalid_0's l2: 83.5169\n",
      "[104]\tvalid_0's l2: 83.2961\n",
      "[105]\tvalid_0's l2: 83.0177\n",
      "[106]\tvalid_0's l2: 82.8064\n",
      "[107]\tvalid_0's l2: 82.6013\n",
      "[108]\tvalid_0's l2: 82.4013\n",
      "[109]\tvalid_0's l2: 82.2051\n",
      "[110]\tvalid_0's l2: 82.0114\n",
      "[111]\tvalid_0's l2: 81.7166\n",
      "[112]\tvalid_0's l2: 81.4244\n",
      "[113]\tvalid_0's l2: 81.2414\n",
      "[114]\tvalid_0's l2: 80.9748\n",
      "[115]\tvalid_0's l2: 80.6968\n",
      "[116]\tvalid_0's l2: 80.4251\n",
      "[117]\tvalid_0's l2: 80.1528\n",
      "[118]\tvalid_0's l2: 79.9028\n",
      "[119]\tvalid_0's l2: 79.6425\n",
      "[120]\tvalid_0's l2: 79.3888\n",
      "[121]\tvalid_0's l2: 79.1404\n",
      "[122]\tvalid_0's l2: 78.8856\n",
      "[123]\tvalid_0's l2: 78.6574\n",
      "[124]\tvalid_0's l2: 78.4192\n",
      "[125]\tvalid_0's l2: 78.1662\n",
      "[126]\tvalid_0's l2: 77.9303\n",
      "[127]\tvalid_0's l2: 77.6796\n",
      "[128]\tvalid_0's l2: 77.4611\n",
      "[129]\tvalid_0's l2: 77.3367\n",
      "[130]\tvalid_0's l2: 77.1312\n",
      "[131]\tvalid_0's l2: 77.0109\n",
      "[132]\tvalid_0's l2: 76.8422\n",
      "[133]\tvalid_0's l2: 76.6155\n",
      "[134]\tvalid_0's l2: 76.3922\n",
      "[135]\tvalid_0's l2: 76.1806\n",
      "[136]\tvalid_0's l2: 76.0739\n",
      "[137]\tvalid_0's l2: 75.8736\n",
      "[138]\tvalid_0's l2: 75.6786\n",
      "[139]\tvalid_0's l2: 75.5128\n",
      "[140]\tvalid_0's l2: 75.3506\n",
      "[141]\tvalid_0's l2: 75.1777\n",
      "[142]\tvalid_0's l2: 75.0854\n",
      "[143]\tvalid_0's l2: 74.9927\n",
      "[144]\tvalid_0's l2: 74.8463\n",
      "[145]\tvalid_0's l2: 74.7532\n",
      "[146]\tvalid_0's l2: 74.6624\n",
      "[147]\tvalid_0's l2: 74.4999\n",
      "[148]\tvalid_0's l2: 74.3396\n",
      "[149]\tvalid_0's l2: 74.2045\n",
      "[150]\tvalid_0's l2: 74.0594\n",
      "[151]\tvalid_0's l2: 73.8846\n",
      "[152]\tvalid_0's l2: 73.8121\n",
      "[153]\tvalid_0's l2: 73.6666\n",
      "[154]\tvalid_0's l2: 73.5241\n",
      "[155]\tvalid_0's l2: 73.3992\n",
      "[156]\tvalid_0's l2: 73.2975\n",
      "[157]\tvalid_0's l2: 73.1642\n",
      "[158]\tvalid_0's l2: 73.0431\n",
      "[159]\tvalid_0's l2: 72.9781\n",
      "[160]\tvalid_0's l2: 72.8622\n",
      "[161]\tvalid_0's l2: 72.7302\n",
      "[162]\tvalid_0's l2: 72.5922\n",
      "[163]\tvalid_0's l2: 72.4636\n",
      "[164]\tvalid_0's l2: 72.3672\n",
      "[165]\tvalid_0's l2: 72.2415\n",
      "[166]\tvalid_0's l2: 72.1504\n",
      "[167]\tvalid_0's l2: 72.0945\n",
      "[168]\tvalid_0's l2: 71.9869\n",
      "[169]\tvalid_0's l2: 71.8741\n",
      "[170]\tvalid_0's l2: 71.7692\n",
      "[171]\tvalid_0's l2: 71.6617\n",
      "[172]\tvalid_0's l2: 71.5702\n",
      "[173]\tvalid_0's l2: 71.5223\n",
      "[174]\tvalid_0's l2: 71.3978\n",
      "[175]\tvalid_0's l2: 71.3136\n",
      "[176]\tvalid_0's l2: 71.2633\n",
      "[177]\tvalid_0's l2: 71.167\n",
      "[178]\tvalid_0's l2: 71.0743\n",
      "[179]\tvalid_0's l2: 70.9796\n",
      "[180]\tvalid_0's l2: 70.9056\n",
      "[181]\tvalid_0's l2: 70.7968\n",
      "[182]\tvalid_0's l2: 70.7069\n",
      "[183]\tvalid_0's l2: 70.6203\n",
      "[184]\tvalid_0's l2: 70.5771\n",
      "[185]\tvalid_0's l2: 70.4808\n",
      "[186]\tvalid_0's l2: 70.3947\n",
      "[187]\tvalid_0's l2: 70.3143\n",
      "[188]\tvalid_0's l2: 70.2449\n",
      "[189]\tvalid_0's l2: 70.2007\n",
      "[190]\tvalid_0's l2: 70.1563\n",
      "[191]\tvalid_0's l2: 70.1217\n",
      "[192]\tvalid_0's l2: 70.0429\n",
      "[193]\tvalid_0's l2: 69.964\n",
      "[194]\tvalid_0's l2: 69.9341\n",
      "[195]\tvalid_0's l2: 69.8445\n",
      "[196]\tvalid_0's l2: 69.8171\n",
      "[197]\tvalid_0's l2: 69.7506\n",
      "[198]\tvalid_0's l2: 69.6793\n",
      "[199]\tvalid_0's l2: 69.6181\n",
      "[200]\tvalid_0's l2: 69.5489\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 69.5489\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 3 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 183.977\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 181.648\n",
      "[3]\tvalid_0's l2: 179.336\n",
      "[4]\tvalid_0's l2: 177.132\n",
      "[5]\tvalid_0's l2: 174.937\n",
      "[6]\tvalid_0's l2: 172.761\n",
      "[7]\tvalid_0's l2: 170.623\n",
      "[8]\tvalid_0's l2: 168.529\n",
      "[9]\tvalid_0's l2: 166.538\n",
      "[10]\tvalid_0's l2: 164.564\n",
      "[11]\tvalid_0's l2: 162.637\n",
      "[12]\tvalid_0's l2: 160.71\n",
      "[13]\tvalid_0's l2: 158.811\n",
      "[14]\tvalid_0's l2: 156.973\n",
      "[15]\tvalid_0's l2: 155.087\n",
      "[16]\tvalid_0's l2: 153.342\n",
      "[17]\tvalid_0's l2: 151.586\n",
      "[18]\tvalid_0's l2: 149.902\n",
      "[19]\tvalid_0's l2: 148.189\n",
      "[20]\tvalid_0's l2: 146.532\n",
      "[21]\tvalid_0's l2: 144.88\n",
      "[22]\tvalid_0's l2: 143.289\n",
      "[23]\tvalid_0's l2: 141.724\n",
      "[24]\tvalid_0's l2: 140.188\n",
      "[25]\tvalid_0's l2: 138.735\n",
      "[26]\tvalid_0's l2: 137.299\n",
      "[27]\tvalid_0's l2: 135.902\n",
      "[28]\tvalid_0's l2: 134.509\n",
      "[29]\tvalid_0's l2: 133.154\n",
      "[30]\tvalid_0's l2: 131.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\tvalid_0's l2: 130.535\n",
      "[32]\tvalid_0's l2: 129.226\n",
      "[33]\tvalid_0's l2: 127.992\n",
      "[34]\tvalid_0's l2: 126.745\n",
      "[35]\tvalid_0's l2: 125.51\n",
      "[36]\tvalid_0's l2: 124.298\n",
      "[37]\tvalid_0's l2: 123.056\n",
      "[38]\tvalid_0's l2: 121.943\n",
      "[39]\tvalid_0's l2: 120.793\n",
      "[40]\tvalid_0's l2: 119.751\n",
      "[41]\tvalid_0's l2: 118.635\n",
      "[42]\tvalid_0's l2: 117.609\n",
      "[43]\tvalid_0's l2: 116.496\n",
      "[44]\tvalid_0's l2: 115.49\n",
      "[45]\tvalid_0's l2: 114.517\n",
      "[46]\tvalid_0's l2: 113.588\n",
      "[47]\tvalid_0's l2: 112.64\n",
      "[48]\tvalid_0's l2: 111.629\n",
      "[49]\tvalid_0's l2: 110.693\n",
      "[50]\tvalid_0's l2: 109.817\n",
      "[51]\tvalid_0's l2: 108.883\n",
      "[52]\tvalid_0's l2: 108.004\n",
      "[53]\tvalid_0's l2: 107.088\n",
      "[54]\tvalid_0's l2: 106.217\n",
      "[55]\tvalid_0's l2: 105.409\n",
      "[56]\tvalid_0's l2: 104.54\n",
      "[57]\tvalid_0's l2: 103.786\n",
      "[58]\tvalid_0's l2: 102.972\n",
      "[59]\tvalid_0's l2: 102.179\n",
      "[60]\tvalid_0's l2: 101.398\n",
      "[61]\tvalid_0's l2: 100.64\n",
      "[62]\tvalid_0's l2: 99.9251\n",
      "[63]\tvalid_0's l2: 99.1783\n",
      "[64]\tvalid_0's l2: 98.4542\n",
      "[65]\tvalid_0's l2: 97.7561\n",
      "[66]\tvalid_0's l2: 97.0411\n",
      "[67]\tvalid_0's l2: 96.3881\n",
      "[68]\tvalid_0's l2: 95.7604\n",
      "[69]\tvalid_0's l2: 95.1534\n",
      "[70]\tvalid_0's l2: 94.5587\n",
      "[71]\tvalid_0's l2: 93.9272\n",
      "[72]\tvalid_0's l2: 93.3021\n",
      "[73]\tvalid_0's l2: 92.7099\n",
      "[74]\tvalid_0's l2: 92.1386\n",
      "[75]\tvalid_0's l2: 91.5445\n",
      "[76]\tvalid_0's l2: 91.0206\n",
      "[77]\tvalid_0's l2: 90.441\n",
      "[78]\tvalid_0's l2: 89.9092\n",
      "[79]\tvalid_0's l2: 89.3875\n",
      "[80]\tvalid_0's l2: 88.8605\n",
      "[81]\tvalid_0's l2: 88.3609\n",
      "[82]\tvalid_0's l2: 87.8847\n",
      "[83]\tvalid_0's l2: 87.3999\n",
      "[84]\tvalid_0's l2: 86.9044\n",
      "[85]\tvalid_0's l2: 86.4121\n",
      "[86]\tvalid_0's l2: 85.9413\n",
      "[87]\tvalid_0's l2: 85.4745\n",
      "[88]\tvalid_0's l2: 84.9953\n",
      "[89]\tvalid_0's l2: 84.5344\n",
      "[90]\tvalid_0's l2: 84.108\n",
      "[91]\tvalid_0's l2: 83.7143\n",
      "[92]\tvalid_0's l2: 83.2778\n",
      "[93]\tvalid_0's l2: 82.847\n",
      "[94]\tvalid_0's l2: 82.4588\n",
      "[95]\tvalid_0's l2: 82.0893\n",
      "[96]\tvalid_0's l2: 81.7205\n",
      "[97]\tvalid_0's l2: 81.356\n",
      "[98]\tvalid_0's l2: 80.9688\n",
      "[99]\tvalid_0's l2: 80.5903\n",
      "[100]\tvalid_0's l2: 80.2064\n",
      "[101]\tvalid_0's l2: 79.8632\n",
      "[102]\tvalid_0's l2: 79.5071\n",
      "[103]\tvalid_0's l2: 79.1523\n",
      "[104]\tvalid_0's l2: 78.8022\n",
      "[105]\tvalid_0's l2: 78.4863\n",
      "[106]\tvalid_0's l2: 78.1466\n",
      "[107]\tvalid_0's l2: 77.8194\n",
      "[108]\tvalid_0's l2: 77.5067\n",
      "[109]\tvalid_0's l2: 77.1864\n",
      "[110]\tvalid_0's l2: 76.881\n",
      "[111]\tvalid_0's l2: 76.5929\n",
      "[112]\tvalid_0's l2: 76.3031\n",
      "[113]\tvalid_0's l2: 76.0144\n",
      "[114]\tvalid_0's l2: 75.7405\n",
      "[115]\tvalid_0's l2: 75.4705\n",
      "[116]\tvalid_0's l2: 75.1964\n",
      "[117]\tvalid_0's l2: 74.9576\n",
      "[118]\tvalid_0's l2: 74.6998\n",
      "[119]\tvalid_0's l2: 74.4662\n",
      "[120]\tvalid_0's l2: 74.2142\n",
      "[121]\tvalid_0's l2: 73.9583\n",
      "[122]\tvalid_0's l2: 73.7143\n",
      "[123]\tvalid_0's l2: 73.5016\n",
      "[124]\tvalid_0's l2: 73.2659\n",
      "[125]\tvalid_0's l2: 73.0653\n",
      "[126]\tvalid_0's l2: 72.8494\n",
      "[127]\tvalid_0's l2: 72.6586\n",
      "[128]\tvalid_0's l2: 72.477\n",
      "[129]\tvalid_0's l2: 72.2449\n",
      "[130]\tvalid_0's l2: 72.0445\n",
      "[131]\tvalid_0's l2: 71.829\n",
      "[132]\tvalid_0's l2: 71.6533\n",
      "[133]\tvalid_0's l2: 71.4691\n",
      "[134]\tvalid_0's l2: 71.296\n",
      "[135]\tvalid_0's l2: 71.1325\n",
      "[136]\tvalid_0's l2: 70.9381\n",
      "[137]\tvalid_0's l2: 70.7833\n",
      "[138]\tvalid_0's l2: 70.6146\n",
      "[139]\tvalid_0's l2: 70.4352\n",
      "[140]\tvalid_0's l2: 70.264\n",
      "[141]\tvalid_0's l2: 70.1227\n",
      "[142]\tvalid_0's l2: 69.9427\n",
      "[143]\tvalid_0's l2: 69.7672\n",
      "[144]\tvalid_0's l2: 69.6344\n",
      "[145]\tvalid_0's l2: 69.4598\n",
      "[146]\tvalid_0's l2: 69.2924\n",
      "[147]\tvalid_0's l2: 69.1452\n",
      "[148]\tvalid_0's l2: 68.991\n",
      "[149]\tvalid_0's l2: 68.8591\n",
      "[150]\tvalid_0's l2: 68.7085\n",
      "[151]\tvalid_0's l2: 68.5777\n",
      "[152]\tvalid_0's l2: 68.4239\n",
      "[153]\tvalid_0's l2: 68.3068\n",
      "[154]\tvalid_0's l2: 68.1879\n",
      "[155]\tvalid_0's l2: 68.0763\n",
      "[156]\tvalid_0's l2: 67.9482\n",
      "[157]\tvalid_0's l2: 67.8408\n",
      "[158]\tvalid_0's l2: 67.7342\n",
      "[159]\tvalid_0's l2: 67.6092\n",
      "[160]\tvalid_0's l2: 67.4984\n",
      "[161]\tvalid_0's l2: 67.3863\n",
      "[162]\tvalid_0's l2: 67.2714\n",
      "[163]\tvalid_0's l2: 67.1802\n",
      "[164]\tvalid_0's l2: 67.0435\n",
      "[165]\tvalid_0's l2: 66.9441\n",
      "[166]\tvalid_0's l2: 66.854\n",
      "[167]\tvalid_0's l2: 66.7411\n",
      "[168]\tvalid_0's l2: 66.6398\n",
      "[169]\tvalid_0's l2: 66.5352\n",
      "[170]\tvalid_0's l2: 66.4578\n",
      "[171]\tvalid_0's l2: 66.3482\n",
      "[172]\tvalid_0's l2: 66.254\n",
      "[173]\tvalid_0's l2: 66.1542\n",
      "[174]\tvalid_0's l2: 66.0912\n",
      "[175]\tvalid_0's l2: 65.9898\n",
      "[176]\tvalid_0's l2: 65.8957\n",
      "[177]\tvalid_0's l2: 65.8069\n",
      "[178]\tvalid_0's l2: 65.7224\n",
      "[179]\tvalid_0's l2: 65.6483\n",
      "[180]\tvalid_0's l2: 65.5735\n",
      "[181]\tvalid_0's l2: 65.4783\n",
      "[182]\tvalid_0's l2: 65.391\n",
      "[183]\tvalid_0's l2: 65.3029\n",
      "[184]\tvalid_0's l2: 65.2234\n",
      "[185]\tvalid_0's l2: 65.1601\n",
      "[186]\tvalid_0's l2: 65.0791\n",
      "[187]\tvalid_0's l2: 65.0027\n",
      "[188]\tvalid_0's l2: 64.94\n",
      "[189]\tvalid_0's l2: 64.8723\n",
      "[190]\tvalid_0's l2: 64.8023\n",
      "[191]\tvalid_0's l2: 64.7286\n",
      "[192]\tvalid_0's l2: 64.663\n",
      "[193]\tvalid_0's l2: 64.5973\n",
      "[194]\tvalid_0's l2: 64.5335\n",
      "[195]\tvalid_0's l2: 64.4858\n",
      "[196]\tvalid_0's l2: 64.4239\n",
      "[197]\tvalid_0's l2: 64.381\n",
      "[198]\tvalid_0's l2: 64.3227\n",
      "[199]\tvalid_0's l2: 64.2641\n",
      "[200]\tvalid_0's l2: 64.2023\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 64.2023\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 4 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.628\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 206.35\n",
      "[3]\tvalid_0's l2: 203.036\n",
      "[4]\tvalid_0's l2: 199.789\n",
      "[5]\tvalid_0's l2: 196.707\n",
      "[6]\tvalid_0's l2: 193.572\n",
      "[7]\tvalid_0's l2: 190.546\n",
      "[8]\tvalid_0's l2: 187.651\n",
      "[9]\tvalid_0's l2: 184.739\n",
      "[10]\tvalid_0's l2: 181.877\n",
      "[11]\tvalid_0's l2: 179.079\n",
      "[12]\tvalid_0's l2: 176.301\n",
      "[13]\tvalid_0's l2: 173.619\n",
      "[14]\tvalid_0's l2: 171.062\n",
      "[15]\tvalid_0's l2: 168.494\n",
      "[16]\tvalid_0's l2: 165.971\n",
      "[17]\tvalid_0's l2: 163.511\n",
      "[18]\tvalid_0's l2: 161.103\n",
      "[19]\tvalid_0's l2: 158.728\n",
      "[20]\tvalid_0's l2: 156.417\n",
      "[21]\tvalid_0's l2: 154.159\n",
      "[22]\tvalid_0's l2: 151.989\n",
      "[23]\tvalid_0's l2: 149.823\n",
      "[24]\tvalid_0's l2: 147.748\n",
      "[25]\tvalid_0's l2: 145.67\n",
      "[26]\tvalid_0's l2: 143.631\n",
      "[27]\tvalid_0's l2: 141.655\n",
      "[28]\tvalid_0's l2: 139.675\n",
      "[29]\tvalid_0's l2: 137.771\n",
      "[30]\tvalid_0's l2: 135.909\n",
      "[31]\tvalid_0's l2: 134.065\n",
      "[32]\tvalid_0's l2: 132.287\n",
      "[33]\tvalid_0's l2: 130.545\n",
      "[34]\tvalid_0's l2: 128.855\n",
      "[35]\tvalid_0's l2: 127.201\n",
      "[36]\tvalid_0's l2: 125.583\n",
      "[37]\tvalid_0's l2: 123.973\n",
      "[38]\tvalid_0's l2: 122.412\n",
      "[39]\tvalid_0's l2: 120.889\n",
      "[40]\tvalid_0's l2: 119.378\n",
      "[41]\tvalid_0's l2: 117.922\n",
      "[42]\tvalid_0's l2: 116.465\n",
      "[43]\tvalid_0's l2: 115.063\n",
      "[44]\tvalid_0's l2: 113.66\n",
      "[45]\tvalid_0's l2: 112.333\n",
      "[46]\tvalid_0's l2: 111.01\n",
      "[47]\tvalid_0's l2: 109.726\n",
      "[48]\tvalid_0's l2: 108.442\n",
      "[49]\tvalid_0's l2: 107.256\n",
      "[50]\tvalid_0's l2: 106.042\n",
      "[51]\tvalid_0's l2: 104.875\n",
      "[52]\tvalid_0's l2: 103.771\n",
      "[53]\tvalid_0's l2: 102.625\n",
      "[54]\tvalid_0's l2: 101.523\n",
      "[55]\tvalid_0's l2: 100.48\n",
      "[56]\tvalid_0's l2: 99.4409\n",
      "[57]\tvalid_0's l2: 98.4021\n",
      "[58]\tvalid_0's l2: 97.396\n",
      "[59]\tvalid_0's l2: 96.4202\n",
      "[60]\tvalid_0's l2: 95.4529\n",
      "[61]\tvalid_0's l2: 94.5584\n",
      "[62]\tvalid_0's l2: 93.6537\n",
      "[63]\tvalid_0's l2: 92.735\n",
      "[64]\tvalid_0's l2: 91.8423\n",
      "[65]\tvalid_0's l2: 90.9914\n",
      "[66]\tvalid_0's l2: 90.138\n",
      "[67]\tvalid_0's l2: 89.3039\n",
      "[68]\tvalid_0's l2: 88.4899\n",
      "[69]\tvalid_0's l2: 87.719\n",
      "[70]\tvalid_0's l2: 86.965\n",
      "[71]\tvalid_0's l2: 86.2266\n",
      "[72]\tvalid_0's l2: 85.4765\n",
      "[73]\tvalid_0's l2: 84.7664\n",
      "[74]\tvalid_0's l2: 84.0889\n",
      "[75]\tvalid_0's l2: 83.3923\n",
      "[76]\tvalid_0's l2: 82.741\n",
      "[77]\tvalid_0's l2: 82.0721\n",
      "[78]\tvalid_0's l2: 81.4363\n",
      "[79]\tvalid_0's l2: 80.8237\n",
      "[80]\tvalid_0's l2: 80.2089\n",
      "[81]\tvalid_0's l2: 79.6274\n",
      "[82]\tvalid_0's l2: 79.0528\n",
      "[83]\tvalid_0's l2: 78.492\n",
      "[84]\tvalid_0's l2: 77.9643\n",
      "[85]\tvalid_0's l2: 77.4211\n",
      "[86]\tvalid_0's l2: 76.9262\n",
      "[87]\tvalid_0's l2: 76.4169\n",
      "[88]\tvalid_0's l2: 75.9325\n",
      "[89]\tvalid_0's l2: 75.4197\n",
      "[90]\tvalid_0's l2: 74.9368\n",
      "[91]\tvalid_0's l2: 74.4853\n",
      "[92]\tvalid_0's l2: 74.0296\n",
      "[93]\tvalid_0's l2: 73.5842\n",
      "[94]\tvalid_0's l2: 73.1542\n",
      "[95]\tvalid_0's l2: 72.7447\n",
      "[96]\tvalid_0's l2: 72.3207\n",
      "[97]\tvalid_0's l2: 71.9183\n",
      "[98]\tvalid_0's l2: 71.4925\n",
      "[99]\tvalid_0's l2: 71.078\n",
      "[100]\tvalid_0's l2: 70.6731\n",
      "[101]\tvalid_0's l2: 70.3033\n",
      "[102]\tvalid_0's l2: 69.9697\n",
      "[103]\tvalid_0's l2: 69.6046\n",
      "[104]\tvalid_0's l2: 69.2394\n",
      "[105]\tvalid_0's l2: 68.9154\n",
      "[106]\tvalid_0's l2: 68.5661\n",
      "[107]\tvalid_0's l2: 68.2223\n",
      "[108]\tvalid_0's l2: 67.8889\n",
      "[109]\tvalid_0's l2: 67.5641\n",
      "[110]\tvalid_0's l2: 67.2442\n",
      "[111]\tvalid_0's l2: 66.9549\n",
      "[112]\tvalid_0's l2: 66.6915\n",
      "[113]\tvalid_0's l2: 66.3915\n",
      "[114]\tvalid_0's l2: 66.1326\n",
      "[115]\tvalid_0's l2: 65.8827\n",
      "[116]\tvalid_0's l2: 65.6092\n",
      "[117]\tvalid_0's l2: 65.3761\n",
      "[118]\tvalid_0's l2: 65.1481\n",
      "[119]\tvalid_0's l2: 64.9294\n",
      "[120]\tvalid_0's l2: 64.7142\n",
      "[121]\tvalid_0's l2: 64.4935\n",
      "[122]\tvalid_0's l2: 64.297\n",
      "[123]\tvalid_0's l2: 64.0828\n",
      "[124]\tvalid_0's l2: 63.8741\n",
      "[125]\tvalid_0's l2: 63.6812\n",
      "[126]\tvalid_0's l2: 63.4846\n",
      "[127]\tvalid_0's l2: 63.3079\n",
      "[128]\tvalid_0's l2: 63.1254\n",
      "[129]\tvalid_0's l2: 62.9114\n",
      "[130]\tvalid_0's l2: 62.7545\n",
      "[131]\tvalid_0's l2: 62.5617\n",
      "[132]\tvalid_0's l2: 62.3998\n",
      "[133]\tvalid_0's l2: 62.2725\n",
      "[134]\tvalid_0's l2: 62.1255\n",
      "[135]\tvalid_0's l2: 61.9689\n",
      "[136]\tvalid_0's l2: 61.7889\n",
      "[137]\tvalid_0's l2: 61.6632\n",
      "[138]\tvalid_0's l2: 61.5323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139]\tvalid_0's l2: 61.4233\n",
      "[140]\tvalid_0's l2: 61.3184\n",
      "[141]\tvalid_0's l2: 61.1902\n",
      "[142]\tvalid_0's l2: 61.0436\n",
      "[143]\tvalid_0's l2: 60.9009\n",
      "[144]\tvalid_0's l2: 60.8022\n",
      "[145]\tvalid_0's l2: 60.6653\n",
      "[146]\tvalid_0's l2: 60.5294\n",
      "[147]\tvalid_0's l2: 60.4305\n",
      "[148]\tvalid_0's l2: 60.3321\n",
      "[149]\tvalid_0's l2: 60.2377\n",
      "[150]\tvalid_0's l2: 60.1539\n",
      "[151]\tvalid_0's l2: 60.077\n",
      "[152]\tvalid_0's l2: 59.9603\n",
      "[153]\tvalid_0's l2: 59.8849\n",
      "[154]\tvalid_0's l2: 59.813\n",
      "[155]\tvalid_0's l2: 59.736\n",
      "[156]\tvalid_0's l2: 59.6674\n",
      "[157]\tvalid_0's l2: 59.6065\n",
      "[158]\tvalid_0's l2: 59.5434\n",
      "[159]\tvalid_0's l2: 59.4455\n",
      "[160]\tvalid_0's l2: 59.4081\n",
      "[161]\tvalid_0's l2: 59.3474\n",
      "[162]\tvalid_0's l2: 59.2933\n",
      "[163]\tvalid_0's l2: 59.2465\n",
      "[164]\tvalid_0's l2: 59.1885\n",
      "[165]\tvalid_0's l2: 59.1383\n",
      "[166]\tvalid_0's l2: 59.0953\n",
      "[167]\tvalid_0's l2: 59.0154\n",
      "[168]\tvalid_0's l2: 58.9915\n",
      "[169]\tvalid_0's l2: 58.9518\n",
      "[170]\tvalid_0's l2: 58.9148\n",
      "[171]\tvalid_0's l2: 58.8778\n",
      "[172]\tvalid_0's l2: 58.8344\n",
      "[173]\tvalid_0's l2: 58.7692\n",
      "[174]\tvalid_0's l2: 58.7445\n",
      "[175]\tvalid_0's l2: 58.704\n",
      "[176]\tvalid_0's l2: 58.6405\n",
      "[177]\tvalid_0's l2: 58.616\n",
      "[178]\tvalid_0's l2: 58.5888\n",
      "[179]\tvalid_0's l2: 58.5709\n",
      "[180]\tvalid_0's l2: 58.5472\n",
      "[181]\tvalid_0's l2: 58.5253\n",
      "[182]\tvalid_0's l2: 58.5141\n",
      "[183]\tvalid_0's l2: 58.4909\n",
      "[184]\tvalid_0's l2: 58.4387\n",
      "[185]\tvalid_0's l2: 58.4319\n",
      "[186]\tvalid_0's l2: 58.4311\n",
      "[187]\tvalid_0's l2: 58.4324\n",
      "[188]\tvalid_0's l2: 58.4193\n",
      "[189]\tvalid_0's l2: 58.3935\n",
      "[190]\tvalid_0's l2: 58.4001\n",
      "[191]\tvalid_0's l2: 58.3616\n",
      "[192]\tvalid_0's l2: 58.3764\n",
      "[193]\tvalid_0's l2: 58.3759\n",
      "[194]\tvalid_0's l2: 58.3605\n",
      "[195]\tvalid_0's l2: 58.3677\n",
      "[196]\tvalid_0's l2: 58.3816\n",
      "[197]\tvalid_0's l2: 58.3938\n",
      "[198]\tvalid_0's l2: 58.3912\n",
      "[199]\tvalid_0's l2: 58.3888\n",
      "[200]\tvalid_0's l2: 58.4056\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[194]\tvalid_0's l2: 58.3605\n",
      "Training Iteration:  194\n",
      "Train:\tValid:\t***** Depth:  8  *****\n",
      "Fold 0 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.531\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 207.455\n",
      "[3]\tvalid_0's l2: 205.324\n",
      "[4]\tvalid_0's l2: 203.241\n",
      "[5]\tvalid_0's l2: 201.303\n",
      "[6]\tvalid_0's l2: 199.334\n",
      "[7]\tvalid_0's l2: 197.39\n",
      "[8]\tvalid_0's l2: 195.611\n",
      "[9]\tvalid_0's l2: 193.786\n",
      "[10]\tvalid_0's l2: 192.02\n",
      "[11]\tvalid_0's l2: 190.261\n",
      "[12]\tvalid_0's l2: 188.526\n",
      "[13]\tvalid_0's l2: 186.823\n",
      "[14]\tvalid_0's l2: 185.309\n",
      "[15]\tvalid_0's l2: 183.772\n",
      "[16]\tvalid_0's l2: 182.288\n",
      "[17]\tvalid_0's l2: 180.757\n",
      "[18]\tvalid_0's l2: 179.337\n",
      "[19]\tvalid_0's l2: 177.926\n",
      "[20]\tvalid_0's l2: 176.535\n",
      "[21]\tvalid_0's l2: 175.197\n",
      "[22]\tvalid_0's l2: 173.979\n",
      "[23]\tvalid_0's l2: 172.775\n",
      "[24]\tvalid_0's l2: 171.626\n",
      "[25]\tvalid_0's l2: 170.449\n",
      "[26]\tvalid_0's l2: 169.316\n",
      "[27]\tvalid_0's l2: 168.303\n",
      "[28]\tvalid_0's l2: 167.252\n",
      "[29]\tvalid_0's l2: 166.196\n",
      "[30]\tvalid_0's l2: 165.204\n",
      "[31]\tvalid_0's l2: 164.197\n",
      "[32]\tvalid_0's l2: 163.261\n",
      "[33]\tvalid_0's l2: 162.405\n",
      "[34]\tvalid_0's l2: 161.515\n",
      "[35]\tvalid_0's l2: 160.673\n",
      "[36]\tvalid_0's l2: 159.87\n",
      "[37]\tvalid_0's l2: 159.088\n",
      "[38]\tvalid_0's l2: 158.299\n",
      "[39]\tvalid_0's l2: 157.548\n",
      "[40]\tvalid_0's l2: 156.829\n",
      "[41]\tvalid_0's l2: 156.14\n",
      "[42]\tvalid_0's l2: 155.481\n",
      "[43]\tvalid_0's l2: 154.778\n",
      "[44]\tvalid_0's l2: 154.12\n",
      "[45]\tvalid_0's l2: 153.475\n",
      "[46]\tvalid_0's l2: 152.886\n",
      "[47]\tvalid_0's l2: 152.278\n",
      "[48]\tvalid_0's l2: 151.695\n",
      "[49]\tvalid_0's l2: 151.144\n",
      "[50]\tvalid_0's l2: 150.622\n",
      "[51]\tvalid_0's l2: 150.117\n",
      "[52]\tvalid_0's l2: 149.671\n",
      "[53]\tvalid_0's l2: 149.201\n",
      "[54]\tvalid_0's l2: 148.739\n",
      "[55]\tvalid_0's l2: 148.273\n",
      "[56]\tvalid_0's l2: 147.878\n",
      "[57]\tvalid_0's l2: 147.517\n",
      "[58]\tvalid_0's l2: 147.141\n",
      "[59]\tvalid_0's l2: 146.792\n",
      "[60]\tvalid_0's l2: 146.437\n",
      "[61]\tvalid_0's l2: 146.112\n",
      "[62]\tvalid_0's l2: 145.744\n",
      "[63]\tvalid_0's l2: 145.436\n",
      "[64]\tvalid_0's l2: 145.116\n",
      "[65]\tvalid_0's l2: 144.843\n",
      "[66]\tvalid_0's l2: 144.561\n",
      "[67]\tvalid_0's l2: 144.239\n",
      "[68]\tvalid_0's l2: 143.959\n",
      "[69]\tvalid_0's l2: 143.672\n",
      "[70]\tvalid_0's l2: 143.437\n",
      "[71]\tvalid_0's l2: 143.226\n",
      "[72]\tvalid_0's l2: 143.019\n",
      "[73]\tvalid_0's l2: 142.82\n",
      "[74]\tvalid_0's l2: 142.654\n",
      "[75]\tvalid_0's l2: 142.44\n",
      "[76]\tvalid_0's l2: 142.249\n",
      "[77]\tvalid_0's l2: 142.065\n",
      "[78]\tvalid_0's l2: 141.927\n",
      "[79]\tvalid_0's l2: 141.813\n",
      "[80]\tvalid_0's l2: 141.643\n",
      "[81]\tvalid_0's l2: 141.505\n",
      "[82]\tvalid_0's l2: 141.404\n",
      "[83]\tvalid_0's l2: 141.297\n",
      "[84]\tvalid_0's l2: 141.193\n",
      "[85]\tvalid_0's l2: 141.11\n",
      "[86]\tvalid_0's l2: 141.021\n",
      "[87]\tvalid_0's l2: 140.919\n",
      "[88]\tvalid_0's l2: 140.871\n",
      "[89]\tvalid_0's l2: 140.78\n",
      "[90]\tvalid_0's l2: 140.731\n",
      "[91]\tvalid_0's l2: 140.663\n",
      "[92]\tvalid_0's l2: 140.614\n",
      "[93]\tvalid_0's l2: 140.538\n",
      "[94]\tvalid_0's l2: 140.517\n",
      "[95]\tvalid_0's l2: 140.485\n",
      "[96]\tvalid_0's l2: 140.451\n",
      "[97]\tvalid_0's l2: 140.409\n",
      "[98]\tvalid_0's l2: 140.383\n",
      "[99]\tvalid_0's l2: 140.379\n",
      "[100]\tvalid_0's l2: 140.36\n",
      "[101]\tvalid_0's l2: 140.422\n",
      "[102]\tvalid_0's l2: 140.445\n",
      "[103]\tvalid_0's l2: 140.443\n",
      "[104]\tvalid_0's l2: 140.411\n",
      "[105]\tvalid_0's l2: 140.44\n",
      "[106]\tvalid_0's l2: 140.448\n",
      "[107]\tvalid_0's l2: 140.448\n",
      "[108]\tvalid_0's l2: 140.473\n",
      "[109]\tvalid_0's l2: 140.481\n",
      "[110]\tvalid_0's l2: 140.503\n",
      "[111]\tvalid_0's l2: 140.607\n",
      "[112]\tvalid_0's l2: 140.664\n",
      "[113]\tvalid_0's l2: 140.673\n",
      "[114]\tvalid_0's l2: 140.74\n",
      "[115]\tvalid_0's l2: 140.798\n",
      "[116]\tvalid_0's l2: 140.84\n",
      "[117]\tvalid_0's l2: 140.934\n",
      "[118]\tvalid_0's l2: 141.009\n",
      "[119]\tvalid_0's l2: 141.111\n",
      "[120]\tvalid_0's l2: 141.134\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's l2: 140.36\n",
      "Training Iteration:  100\n",
      "Train:\tValid:\tFold 1 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 209.387\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 207.306\n",
      "[3]\tvalid_0's l2: 204.938\n",
      "[4]\tvalid_0's l2: 202.61\n",
      "[5]\tvalid_0's l2: 200.661\n",
      "[6]\tvalid_0's l2: 198.468\n",
      "[7]\tvalid_0's l2: 196.313\n",
      "[8]\tvalid_0's l2: 194.491\n",
      "[9]\tvalid_0's l2: 192.436\n",
      "[10]\tvalid_0's l2: 190.415\n",
      "[11]\tvalid_0's l2: 188.418\n",
      "[12]\tvalid_0's l2: 186.491\n",
      "[13]\tvalid_0's l2: 184.595\n",
      "[14]\tvalid_0's l2: 182.995\n",
      "[15]\tvalid_0's l2: 181.169\n",
      "[16]\tvalid_0's l2: 179.424\n",
      "[17]\tvalid_0's l2: 177.7\n",
      "[18]\tvalid_0's l2: 176.01\n",
      "[19]\tvalid_0's l2: 174.338\n",
      "[20]\tvalid_0's l2: 172.74\n",
      "[21]\tvalid_0's l2: 171.162\n",
      "[22]\tvalid_0's l2: 169.817\n",
      "[23]\tvalid_0's l2: 168.336\n",
      "[24]\tvalid_0's l2: 167.055\n",
      "[25]\tvalid_0's l2: 165.599\n",
      "[26]\tvalid_0's l2: 164.216\n",
      "[27]\tvalid_0's l2: 162.824\n",
      "[28]\tvalid_0's l2: 161.488\n",
      "[29]\tvalid_0's l2: 160.161\n",
      "[30]\tvalid_0's l2: 158.867\n",
      "[31]\tvalid_0's l2: 157.615\n",
      "[32]\tvalid_0's l2: 156.417\n",
      "[33]\tvalid_0's l2: 155.203\n",
      "[34]\tvalid_0's l2: 154.02\n",
      "[35]\tvalid_0's l2: 153.015\n",
      "[36]\tvalid_0's l2: 152.03\n",
      "[37]\tvalid_0's l2: 150.934\n",
      "[38]\tvalid_0's l2: 149.882\n",
      "[39]\tvalid_0's l2: 148.967\n",
      "[40]\tvalid_0's l2: 147.922\n",
      "[41]\tvalid_0's l2: 147.047\n",
      "[42]\tvalid_0's l2: 146.057\n",
      "[43]\tvalid_0's l2: 145.099\n",
      "[44]\tvalid_0's l2: 144.132\n",
      "[45]\tvalid_0's l2: 143.21\n",
      "[46]\tvalid_0's l2: 142.318\n",
      "[47]\tvalid_0's l2: 141.432\n",
      "[48]\tvalid_0's l2: 140.564\n",
      "[49]\tvalid_0's l2: 139.771\n",
      "[50]\tvalid_0's l2: 138.93\n",
      "[51]\tvalid_0's l2: 138.233\n",
      "[52]\tvalid_0's l2: 137.43\n",
      "[53]\tvalid_0's l2: 136.706\n",
      "[54]\tvalid_0's l2: 136.039\n",
      "[55]\tvalid_0's l2: 135.295\n",
      "[56]\tvalid_0's l2: 134.549\n",
      "[57]\tvalid_0's l2: 133.861\n",
      "[58]\tvalid_0's l2: 133.264\n",
      "[59]\tvalid_0's l2: 132.572\n",
      "[60]\tvalid_0's l2: 132.003\n",
      "[61]\tvalid_0's l2: 131.354\n",
      "[62]\tvalid_0's l2: 130.746\n",
      "[63]\tvalid_0's l2: 130.21\n",
      "[64]\tvalid_0's l2: 129.689\n",
      "[65]\tvalid_0's l2: 129.099\n",
      "[66]\tvalid_0's l2: 128.513\n",
      "[67]\tvalid_0's l2: 127.925\n",
      "[68]\tvalid_0's l2: 127.341\n",
      "[69]\tvalid_0's l2: 126.818\n",
      "[70]\tvalid_0's l2: 126.271\n",
      "[71]\tvalid_0's l2: 125.766\n",
      "[72]\tvalid_0's l2: 125.337\n",
      "[73]\tvalid_0's l2: 124.845\n",
      "[74]\tvalid_0's l2: 124.39\n",
      "[75]\tvalid_0's l2: 123.915\n",
      "[76]\tvalid_0's l2: 123.421\n",
      "[77]\tvalid_0's l2: 123.044\n",
      "[78]\tvalid_0's l2: 122.623\n",
      "[79]\tvalid_0's l2: 122.243\n",
      "[80]\tvalid_0's l2: 121.828\n",
      "[81]\tvalid_0's l2: 121.479\n",
      "[82]\tvalid_0's l2: 121.12\n",
      "[83]\tvalid_0's l2: 120.723\n",
      "[84]\tvalid_0's l2: 120.36\n",
      "[85]\tvalid_0's l2: 120.033\n",
      "[86]\tvalid_0's l2: 119.657\n",
      "[87]\tvalid_0's l2: 119.32\n",
      "[88]\tvalid_0's l2: 119.003\n",
      "[89]\tvalid_0's l2: 118.723\n",
      "[90]\tvalid_0's l2: 118.403\n",
      "[91]\tvalid_0's l2: 118.084\n",
      "[92]\tvalid_0's l2: 117.778\n",
      "[93]\tvalid_0's l2: 117.499\n",
      "[94]\tvalid_0's l2: 117.217\n",
      "[95]\tvalid_0's l2: 116.946\n",
      "[96]\tvalid_0's l2: 116.688\n",
      "[97]\tvalid_0's l2: 116.413\n",
      "[98]\tvalid_0's l2: 116.19\n",
      "[99]\tvalid_0's l2: 115.975\n",
      "[100]\tvalid_0's l2: 115.764\n",
      "[101]\tvalid_0's l2: 115.537\n",
      "[102]\tvalid_0's l2: 115.278\n",
      "[103]\tvalid_0's l2: 115.078\n",
      "[104]\tvalid_0's l2: 114.891\n",
      "[105]\tvalid_0's l2: 114.67\n",
      "[106]\tvalid_0's l2: 114.494\n",
      "[107]\tvalid_0's l2: 114.327\n",
      "[108]\tvalid_0's l2: 114.16\n",
      "[109]\tvalid_0's l2: 114.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110]\tvalid_0's l2: 113.842\n",
      "[111]\tvalid_0's l2: 113.637\n",
      "[112]\tvalid_0's l2: 113.495\n",
      "[113]\tvalid_0's l2: 113.354\n",
      "[114]\tvalid_0's l2: 113.176\n",
      "[115]\tvalid_0's l2: 113.032\n",
      "[116]\tvalid_0's l2: 112.842\n",
      "[117]\tvalid_0's l2: 112.722\n",
      "[118]\tvalid_0's l2: 112.549\n",
      "[119]\tvalid_0's l2: 112.396\n",
      "[120]\tvalid_0's l2: 112.251\n",
      "[121]\tvalid_0's l2: 112.109\n",
      "[122]\tvalid_0's l2: 111.987\n",
      "[123]\tvalid_0's l2: 111.838\n",
      "[124]\tvalid_0's l2: 111.703\n",
      "[125]\tvalid_0's l2: 111.573\n",
      "[126]\tvalid_0's l2: 111.436\n",
      "[127]\tvalid_0's l2: 111.356\n",
      "[128]\tvalid_0's l2: 111.198\n",
      "[129]\tvalid_0's l2: 111.091\n",
      "[130]\tvalid_0's l2: 111.001\n",
      "[131]\tvalid_0's l2: 110.886\n",
      "[132]\tvalid_0's l2: 110.774\n",
      "[133]\tvalid_0's l2: 110.649\n",
      "[134]\tvalid_0's l2: 110.515\n",
      "[135]\tvalid_0's l2: 110.389\n",
      "[136]\tvalid_0's l2: 110.293\n",
      "[137]\tvalid_0's l2: 110.164\n",
      "[138]\tvalid_0's l2: 110.119\n",
      "[139]\tvalid_0's l2: 109.99\n",
      "[140]\tvalid_0's l2: 109.885\n",
      "[141]\tvalid_0's l2: 109.787\n",
      "[142]\tvalid_0's l2: 109.718\n",
      "[143]\tvalid_0's l2: 109.653\n",
      "[144]\tvalid_0's l2: 109.615\n",
      "[145]\tvalid_0's l2: 109.561\n",
      "[146]\tvalid_0's l2: 109.51\n",
      "[147]\tvalid_0's l2: 109.413\n",
      "[148]\tvalid_0's l2: 109.287\n",
      "[149]\tvalid_0's l2: 109.159\n",
      "[150]\tvalid_0's l2: 109.117\n",
      "[151]\tvalid_0's l2: 108.987\n",
      "[152]\tvalid_0's l2: 108.941\n",
      "[153]\tvalid_0's l2: 108.857\n",
      "[154]\tvalid_0's l2: 108.737\n",
      "[155]\tvalid_0's l2: 108.617\n",
      "[156]\tvalid_0's l2: 108.499\n",
      "[157]\tvalid_0's l2: 108.395\n",
      "[158]\tvalid_0's l2: 108.285\n",
      "[159]\tvalid_0's l2: 108.248\n",
      "[160]\tvalid_0's l2: 108.139\n",
      "[161]\tvalid_0's l2: 108.039\n",
      "[162]\tvalid_0's l2: 107.936\n",
      "[163]\tvalid_0's l2: 107.836\n",
      "[164]\tvalid_0's l2: 107.745\n",
      "[165]\tvalid_0's l2: 107.649\n",
      "[166]\tvalid_0's l2: 107.587\n",
      "[167]\tvalid_0's l2: 107.561\n",
      "[168]\tvalid_0's l2: 107.48\n",
      "[169]\tvalid_0's l2: 107.381\n",
      "[170]\tvalid_0's l2: 107.337\n",
      "[171]\tvalid_0's l2: 107.275\n",
      "[172]\tvalid_0's l2: 107.208\n",
      "[173]\tvalid_0's l2: 107.188\n",
      "[174]\tvalid_0's l2: 107.148\n",
      "[175]\tvalid_0's l2: 107.037\n",
      "[176]\tvalid_0's l2: 107.013\n",
      "[177]\tvalid_0's l2: 106.959\n",
      "[178]\tvalid_0's l2: 106.91\n",
      "[179]\tvalid_0's l2: 106.823\n",
      "[180]\tvalid_0's l2: 106.727\n",
      "[181]\tvalid_0's l2: 106.672\n",
      "[182]\tvalid_0's l2: 106.614\n",
      "[183]\tvalid_0's l2: 106.569\n",
      "[184]\tvalid_0's l2: 106.556\n",
      "[185]\tvalid_0's l2: 106.525\n",
      "[186]\tvalid_0's l2: 106.459\n",
      "[187]\tvalid_0's l2: 106.363\n",
      "[188]\tvalid_0's l2: 106.308\n",
      "[189]\tvalid_0's l2: 106.262\n",
      "[190]\tvalid_0's l2: 106.242\n",
      "[191]\tvalid_0's l2: 106.245\n",
      "[192]\tvalid_0's l2: 106.188\n",
      "[193]\tvalid_0's l2: 106.167\n",
      "[194]\tvalid_0's l2: 106.154\n",
      "[195]\tvalid_0's l2: 106.1\n",
      "[196]\tvalid_0's l2: 106.086\n",
      "[197]\tvalid_0's l2: 106.078\n",
      "[198]\tvalid_0's l2: 106.097\n",
      "[199]\tvalid_0's l2: 106.119\n",
      "[200]\tvalid_0's l2: 106.077\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 106.077\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 2 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 173.668\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 171.808\n",
      "[3]\tvalid_0's l2: 169.733\n",
      "[4]\tvalid_0's l2: 167.703\n",
      "[5]\tvalid_0's l2: 165.979\n",
      "[6]\tvalid_0's l2: 164.03\n",
      "[7]\tvalid_0's l2: 162.116\n",
      "[8]\tvalid_0's l2: 160.491\n",
      "[9]\tvalid_0's l2: 158.609\n",
      "[10]\tvalid_0's l2: 156.813\n",
      "[11]\tvalid_0's l2: 155.028\n",
      "[12]\tvalid_0's l2: 153.301\n",
      "[13]\tvalid_0's l2: 151.581\n",
      "[14]\tvalid_0's l2: 150.136\n",
      "[15]\tvalid_0's l2: 148.472\n",
      "[16]\tvalid_0's l2: 146.841\n",
      "[17]\tvalid_0's l2: 145.209\n",
      "[18]\tvalid_0's l2: 143.671\n",
      "[19]\tvalid_0's l2: 142.133\n",
      "[20]\tvalid_0's l2: 140.667\n",
      "[21]\tvalid_0's l2: 139.222\n",
      "[22]\tvalid_0's l2: 138.017\n",
      "[23]\tvalid_0's l2: 136.624\n",
      "[24]\tvalid_0's l2: 135.466\n",
      "[25]\tvalid_0's l2: 134.157\n",
      "[26]\tvalid_0's l2: 132.854\n",
      "[27]\tvalid_0's l2: 131.529\n",
      "[28]\tvalid_0's l2: 130.272\n",
      "[29]\tvalid_0's l2: 129.041\n",
      "[30]\tvalid_0's l2: 127.804\n",
      "[31]\tvalid_0's l2: 126.618\n",
      "[32]\tvalid_0's l2: 125.5\n",
      "[33]\tvalid_0's l2: 124.364\n",
      "[34]\tvalid_0's l2: 123.258\n",
      "[35]\tvalid_0's l2: 122.34\n",
      "[36]\tvalid_0's l2: 121.443\n",
      "[37]\tvalid_0's l2: 120.422\n",
      "[38]\tvalid_0's l2: 119.377\n",
      "[39]\tvalid_0's l2: 118.512\n",
      "[40]\tvalid_0's l2: 117.505\n",
      "[41]\tvalid_0's l2: 116.701\n",
      "[42]\tvalid_0's l2: 115.755\n",
      "[43]\tvalid_0's l2: 114.831\n",
      "[44]\tvalid_0's l2: 113.93\n",
      "[45]\tvalid_0's l2: 113.011\n",
      "[46]\tvalid_0's l2: 112.112\n",
      "[47]\tvalid_0's l2: 111.238\n",
      "[48]\tvalid_0's l2: 110.413\n",
      "[49]\tvalid_0's l2: 109.562\n",
      "[50]\tvalid_0's l2: 108.768\n",
      "[51]\tvalid_0's l2: 108.089\n",
      "[52]\tvalid_0's l2: 107.311\n",
      "[53]\tvalid_0's l2: 106.564\n",
      "[54]\tvalid_0's l2: 105.926\n",
      "[55]\tvalid_0's l2: 105.209\n",
      "[56]\tvalid_0's l2: 104.502\n",
      "[57]\tvalid_0's l2: 103.821\n",
      "[58]\tvalid_0's l2: 103.233\n",
      "[59]\tvalid_0's l2: 102.535\n",
      "[60]\tvalid_0's l2: 101.974\n",
      "[61]\tvalid_0's l2: 101.316\n",
      "[62]\tvalid_0's l2: 100.644\n",
      "[63]\tvalid_0's l2: 100.117\n",
      "[64]\tvalid_0's l2: 99.6061\n",
      "[65]\tvalid_0's l2: 98.9935\n",
      "[66]\tvalid_0's l2: 98.4171\n",
      "[67]\tvalid_0's l2: 97.8351\n",
      "[68]\tvalid_0's l2: 97.2796\n",
      "[69]\tvalid_0's l2: 96.7027\n",
      "[70]\tvalid_0's l2: 96.1635\n",
      "[71]\tvalid_0's l2: 95.6319\n",
      "[72]\tvalid_0's l2: 95.2002\n",
      "[73]\tvalid_0's l2: 94.6346\n",
      "[74]\tvalid_0's l2: 94.1333\n",
      "[75]\tvalid_0's l2: 93.6345\n",
      "[76]\tvalid_0's l2: 93.1434\n",
      "[77]\tvalid_0's l2: 92.7498\n",
      "[78]\tvalid_0's l2: 92.2897\n",
      "[79]\tvalid_0's l2: 91.7905\n",
      "[80]\tvalid_0's l2: 91.3664\n",
      "[81]\tvalid_0's l2: 90.9553\n",
      "[82]\tvalid_0's l2: 90.5514\n",
      "[83]\tvalid_0's l2: 90.1196\n",
      "[84]\tvalid_0's l2: 89.7176\n",
      "[85]\tvalid_0's l2: 89.3234\n",
      "[86]\tvalid_0's l2: 88.9348\n",
      "[87]\tvalid_0's l2: 88.548\n",
      "[88]\tvalid_0's l2: 88.1834\n",
      "[89]\tvalid_0's l2: 87.8829\n",
      "[90]\tvalid_0's l2: 87.5173\n",
      "[91]\tvalid_0's l2: 87.1538\n",
      "[92]\tvalid_0's l2: 86.8303\n",
      "[93]\tvalid_0's l2: 86.4894\n",
      "[94]\tvalid_0's l2: 86.0934\n",
      "[95]\tvalid_0's l2: 85.765\n",
      "[96]\tvalid_0's l2: 85.4508\n",
      "[97]\tvalid_0's l2: 85.1304\n",
      "[98]\tvalid_0's l2: 84.8804\n",
      "[99]\tvalid_0's l2: 84.6357\n",
      "[100]\tvalid_0's l2: 84.3971\n",
      "[101]\tvalid_0's l2: 84.1244\n",
      "[102]\tvalid_0's l2: 83.796\n",
      "[103]\tvalid_0's l2: 83.4446\n",
      "[104]\tvalid_0's l2: 83.2246\n",
      "[105]\tvalid_0's l2: 82.9591\n",
      "[106]\tvalid_0's l2: 82.7499\n",
      "[107]\tvalid_0's l2: 82.5449\n",
      "[108]\tvalid_0's l2: 82.3461\n",
      "[109]\tvalid_0's l2: 82.1529\n",
      "[110]\tvalid_0's l2: 81.968\n",
      "[111]\tvalid_0's l2: 81.675\n",
      "[112]\tvalid_0's l2: 81.3927\n",
      "[113]\tvalid_0's l2: 81.2127\n",
      "[114]\tvalid_0's l2: 80.9351\n",
      "[115]\tvalid_0's l2: 80.6549\n",
      "[116]\tvalid_0's l2: 80.3905\n",
      "[117]\tvalid_0's l2: 80.1104\n",
      "[118]\tvalid_0's l2: 79.8583\n",
      "[119]\tvalid_0's l2: 79.5983\n",
      "[120]\tvalid_0's l2: 79.354\n",
      "[121]\tvalid_0's l2: 79.1081\n",
      "[122]\tvalid_0's l2: 78.8872\n",
      "[123]\tvalid_0's l2: 78.673\n",
      "[124]\tvalid_0's l2: 78.4374\n",
      "[125]\tvalid_0's l2: 78.2521\n",
      "[126]\tvalid_0's l2: 78.0399\n",
      "[127]\tvalid_0's l2: 77.8056\n",
      "[128]\tvalid_0's l2: 77.5948\n",
      "[129]\tvalid_0's l2: 77.4644\n",
      "[130]\tvalid_0's l2: 77.2614\n",
      "[131]\tvalid_0's l2: 77.1413\n",
      "[132]\tvalid_0's l2: 76.9445\n",
      "[133]\tvalid_0's l2: 76.7483\n",
      "[134]\tvalid_0's l2: 76.5609\n",
      "[135]\tvalid_0's l2: 76.3659\n",
      "[136]\tvalid_0's l2: 76.2559\n",
      "[137]\tvalid_0's l2: 76.0694\n",
      "[138]\tvalid_0's l2: 75.8843\n",
      "[139]\tvalid_0's l2: 75.7135\n",
      "[140]\tvalid_0's l2: 75.5306\n",
      "[141]\tvalid_0's l2: 75.3566\n",
      "[142]\tvalid_0's l2: 75.2634\n",
      "[143]\tvalid_0's l2: 75.1629\n",
      "[144]\tvalid_0's l2: 75.004\n",
      "[145]\tvalid_0's l2: 74.9155\n",
      "[146]\tvalid_0's l2: 74.8289\n",
      "[147]\tvalid_0's l2: 74.654\n",
      "[148]\tvalid_0's l2: 74.4909\n",
      "[149]\tvalid_0's l2: 74.3415\n",
      "[150]\tvalid_0's l2: 74.173\n",
      "[151]\tvalid_0's l2: 74.0163\n",
      "[152]\tvalid_0's l2: 73.939\n",
      "[153]\tvalid_0's l2: 73.8051\n",
      "[154]\tvalid_0's l2: 73.6734\n",
      "[155]\tvalid_0's l2: 73.5214\n",
      "[156]\tvalid_0's l2: 73.3992\n",
      "[157]\tvalid_0's l2: 73.2625\n",
      "[158]\tvalid_0's l2: 73.143\n",
      "[159]\tvalid_0's l2: 73.0804\n",
      "[160]\tvalid_0's l2: 72.9592\n",
      "[161]\tvalid_0's l2: 72.842\n",
      "[162]\tvalid_0's l2: 72.7256\n",
      "[163]\tvalid_0's l2: 72.59\n",
      "[164]\tvalid_0's l2: 72.4659\n",
      "[165]\tvalid_0's l2: 72.3263\n",
      "[166]\tvalid_0's l2: 72.2205\n",
      "[167]\tvalid_0's l2: 72.16\n",
      "[168]\tvalid_0's l2: 72.0388\n",
      "[169]\tvalid_0's l2: 71.9298\n",
      "[170]\tvalid_0's l2: 71.8114\n",
      "[171]\tvalid_0's l2: 71.6975\n",
      "[172]\tvalid_0's l2: 71.5782\n",
      "[173]\tvalid_0's l2: 71.5261\n",
      "[174]\tvalid_0's l2: 71.426\n",
      "[175]\tvalid_0's l2: 71.3237\n",
      "[176]\tvalid_0's l2: 71.2887\n",
      "[177]\tvalid_0's l2: 71.1822\n",
      "[178]\tvalid_0's l2: 71.0831\n",
      "[179]\tvalid_0's l2: 70.9832\n",
      "[180]\tvalid_0's l2: 70.8834\n",
      "[181]\tvalid_0's l2: 70.7891\n",
      "[182]\tvalid_0's l2: 70.7143\n",
      "[183]\tvalid_0's l2: 70.6165\n",
      "[184]\tvalid_0's l2: 70.583\n",
      "[185]\tvalid_0's l2: 70.53\n",
      "[186]\tvalid_0's l2: 70.429\n",
      "[187]\tvalid_0's l2: 70.338\n",
      "[188]\tvalid_0's l2: 70.2471\n",
      "[189]\tvalid_0's l2: 70.1661\n",
      "[190]\tvalid_0's l2: 70.1011\n",
      "[191]\tvalid_0's l2: 70.0756\n",
      "[192]\tvalid_0's l2: 70.0069\n",
      "[193]\tvalid_0's l2: 69.9254\n",
      "[194]\tvalid_0's l2: 69.8511\n",
      "[195]\tvalid_0's l2: 69.8024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196]\tvalid_0's l2: 69.7523\n",
      "[197]\tvalid_0's l2: 69.6835\n",
      "[198]\tvalid_0's l2: 69.6027\n",
      "[199]\tvalid_0's l2: 69.5265\n",
      "[200]\tvalid_0's l2: 69.4469\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 69.4469\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\tFold 3 :\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's l2: 183.972\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 181.645\n",
      "[3]\tvalid_0's l2: 179.301\n",
      "[4]\tvalid_0's l2: 177.009\n",
      "[5]\tvalid_0's l2: 174.792\n",
      "[6]\tvalid_0's l2: 172.589\n",
      "[7]\tvalid_0's l2: 170.461\n",
      "[8]\tvalid_0's l2: 168.373\n",
      "[9]\tvalid_0's l2: 166.289\n",
      "[10]\tvalid_0's l2: 164.251\n",
      "[11]\tvalid_0's l2: 162.276\n",
      "[12]\tvalid_0's l2: 160.328\n",
      "[13]\tvalid_0's l2: 158.443\n",
      "[14]\tvalid_0's l2: 156.588\n",
      "[15]\tvalid_0's l2: 154.698\n",
      "[16]\tvalid_0's l2: 152.889\n",
      "[17]\tvalid_0's l2: 151.151\n",
      "[18]\tvalid_0's l2: 149.414\n",
      "[19]\tvalid_0's l2: 147.696\n",
      "[20]\tvalid_0's l2: 146.066\n",
      "[21]\tvalid_0's l2: 144.429\n",
      "[22]\tvalid_0's l2: 142.838\n",
      "[23]\tvalid_0's l2: 141.341\n",
      "[24]\tvalid_0's l2: 139.814\n",
      "[25]\tvalid_0's l2: 138.288\n",
      "[26]\tvalid_0's l2: 136.803\n",
      "[27]\tvalid_0's l2: 135.375\n",
      "[28]\tvalid_0's l2: 133.933\n",
      "[29]\tvalid_0's l2: 132.535\n",
      "[30]\tvalid_0's l2: 131.158\n",
      "[31]\tvalid_0's l2: 129.811\n",
      "[32]\tvalid_0's l2: 128.449\n",
      "[33]\tvalid_0's l2: 127.172\n",
      "[34]\tvalid_0's l2: 125.916\n",
      "[35]\tvalid_0's l2: 124.67\n",
      "[36]\tvalid_0's l2: 123.449\n",
      "[37]\tvalid_0's l2: 122.291\n",
      "[38]\tvalid_0's l2: 121.125\n",
      "[39]\tvalid_0's l2: 119.975\n",
      "[40]\tvalid_0's l2: 118.85\n",
      "[41]\tvalid_0's l2: 117.744\n",
      "[42]\tvalid_0's l2: 116.66\n",
      "[43]\tvalid_0's l2: 115.559\n",
      "[44]\tvalid_0's l2: 114.522\n",
      "[45]\tvalid_0's l2: 113.51\n",
      "[46]\tvalid_0's l2: 112.566\n",
      "[47]\tvalid_0's l2: 111.588\n",
      "[48]\tvalid_0's l2: 110.583\n",
      "[49]\tvalid_0's l2: 109.617\n",
      "[50]\tvalid_0's l2: 108.724\n",
      "[51]\tvalid_0's l2: 107.807\n",
      "[52]\tvalid_0's l2: 106.966\n",
      "[53]\tvalid_0's l2: 106.104\n",
      "[54]\tvalid_0's l2: 105.236\n",
      "[55]\tvalid_0's l2: 104.397\n",
      "[56]\tvalid_0's l2: 103.583\n",
      "[57]\tvalid_0's l2: 102.787\n",
      "[58]\tvalid_0's l2: 101.988\n",
      "[59]\tvalid_0's l2: 101.198\n",
      "[60]\tvalid_0's l2: 100.424\n",
      "[61]\tvalid_0's l2: 99.6891\n",
      "[62]\tvalid_0's l2: 98.9706\n",
      "[63]\tvalid_0's l2: 98.242\n",
      "[64]\tvalid_0's l2: 97.5131\n",
      "[65]\tvalid_0's l2: 96.8311\n",
      "[66]\tvalid_0's l2: 96.1817\n",
      "[67]\tvalid_0's l2: 95.5514\n",
      "[68]\tvalid_0's l2: 94.9326\n",
      "[69]\tvalid_0's l2: 94.3101\n",
      "[70]\tvalid_0's l2: 93.7126\n",
      "[71]\tvalid_0's l2: 93.1325\n",
      "[72]\tvalid_0's l2: 92.505\n",
      "[73]\tvalid_0's l2: 91.9296\n",
      "[74]\tvalid_0's l2: 91.3599\n",
      "[75]\tvalid_0's l2: 90.7979\n",
      "[76]\tvalid_0's l2: 90.2298\n",
      "[77]\tvalid_0's l2: 89.6541\n",
      "[78]\tvalid_0's l2: 89.1219\n",
      "[79]\tvalid_0's l2: 88.6102\n",
      "[80]\tvalid_0's l2: 88.0999\n",
      "[81]\tvalid_0's l2: 87.5874\n",
      "[82]\tvalid_0's l2: 87.0934\n",
      "[83]\tvalid_0's l2: 86.5939\n",
      "[84]\tvalid_0's l2: 86.1006\n",
      "[85]\tvalid_0's l2: 85.656\n",
      "[86]\tvalid_0's l2: 85.1908\n",
      "[87]\tvalid_0's l2: 84.7228\n",
      "[88]\tvalid_0's l2: 84.2815\n",
      "[89]\tvalid_0's l2: 83.8205\n",
      "[90]\tvalid_0's l2: 83.3807\n",
      "[91]\tvalid_0's l2: 82.9658\n",
      "[92]\tvalid_0's l2: 82.5301\n",
      "[93]\tvalid_0's l2: 82.128\n",
      "[94]\tvalid_0's l2: 81.7441\n",
      "[95]\tvalid_0's l2: 81.3705\n",
      "[96]\tvalid_0's l2: 80.9708\n",
      "[97]\tvalid_0's l2: 80.5995\n",
      "[98]\tvalid_0's l2: 80.209\n",
      "[99]\tvalid_0's l2: 79.8173\n",
      "[100]\tvalid_0's l2: 79.443\n",
      "[101]\tvalid_0's l2: 79.1096\n",
      "[102]\tvalid_0's l2: 78.7779\n",
      "[103]\tvalid_0's l2: 78.4317\n",
      "[104]\tvalid_0's l2: 78.0819\n",
      "[105]\tvalid_0's l2: 77.7709\n",
      "[106]\tvalid_0's l2: 77.431\n",
      "[107]\tvalid_0's l2: 77.1027\n",
      "[108]\tvalid_0's l2: 76.7789\n",
      "[109]\tvalid_0's l2: 76.4579\n",
      "[110]\tvalid_0's l2: 76.1553\n",
      "[111]\tvalid_0's l2: 75.8502\n",
      "[112]\tvalid_0's l2: 75.5676\n",
      "[113]\tvalid_0's l2: 75.2844\n",
      "[114]\tvalid_0's l2: 75.0079\n",
      "[115]\tvalid_0's l2: 74.7191\n",
      "[116]\tvalid_0's l2: 74.4464\n",
      "[117]\tvalid_0's l2: 74.1626\n",
      "[118]\tvalid_0's l2: 73.9215\n",
      "[119]\tvalid_0's l2: 73.661\n",
      "[120]\tvalid_0's l2: 73.4257\n",
      "[121]\tvalid_0's l2: 73.1773\n",
      "[122]\tvalid_0's l2: 72.9397\n",
      "[123]\tvalid_0's l2: 72.7267\n",
      "[124]\tvalid_0's l2: 72.48\n",
      "[125]\tvalid_0's l2: 72.252\n",
      "[126]\tvalid_0's l2: 72.0314\n",
      "[127]\tvalid_0's l2: 71.7943\n",
      "[128]\tvalid_0's l2: 71.5936\n",
      "[129]\tvalid_0's l2: 71.3787\n",
      "[130]\tvalid_0's l2: 71.1738\n",
      "[131]\tvalid_0's l2: 70.9517\n",
      "[132]\tvalid_0's l2: 70.7826\n",
      "[133]\tvalid_0's l2: 70.5985\n",
      "[134]\tvalid_0's l2: 70.4325\n",
      "[135]\tvalid_0's l2: 70.2522\n",
      "[136]\tvalid_0's l2: 70.061\n",
      "[137]\tvalid_0's l2: 69.9017\n",
      "[138]\tvalid_0's l2: 69.7337\n",
      "[139]\tvalid_0's l2: 69.5649\n",
      "[140]\tvalid_0's l2: 69.3793\n",
      "[141]\tvalid_0's l2: 69.2223\n",
      "[142]\tvalid_0's l2: 69.0481\n",
      "[143]\tvalid_0's l2: 68.8683\n",
      "[144]\tvalid_0's l2: 68.7159\n",
      "[145]\tvalid_0's l2: 68.5432\n",
      "[146]\tvalid_0's l2: 68.3844\n",
      "[147]\tvalid_0's l2: 68.2348\n",
      "[148]\tvalid_0's l2: 68.087\n",
      "[149]\tvalid_0's l2: 67.9457\n",
      "[150]\tvalid_0's l2: 67.8118\n",
      "[151]\tvalid_0's l2: 67.6752\n",
      "[152]\tvalid_0's l2: 67.523\n",
      "[153]\tvalid_0's l2: 67.3994\n",
      "[154]\tvalid_0's l2: 67.2992\n",
      "[155]\tvalid_0's l2: 67.161\n",
      "[156]\tvalid_0's l2: 67.0209\n",
      "[157]\tvalid_0's l2: 66.9029\n",
      "[158]\tvalid_0's l2: 66.7801\n",
      "[159]\tvalid_0's l2: 66.6528\n",
      "[160]\tvalid_0's l2: 66.5408\n",
      "[161]\tvalid_0's l2: 66.4332\n",
      "[162]\tvalid_0's l2: 66.3231\n",
      "[163]\tvalid_0's l2: 66.2057\n",
      "[164]\tvalid_0's l2: 66.103\n",
      "[165]\tvalid_0's l2: 65.9966\n",
      "[166]\tvalid_0's l2: 65.9037\n",
      "[167]\tvalid_0's l2: 65.7934\n",
      "[168]\tvalid_0's l2: 65.6885\n",
      "[169]\tvalid_0's l2: 65.5844\n",
      "[170]\tvalid_0's l2: 65.4995\n",
      "[171]\tvalid_0's l2: 65.4007\n",
      "[172]\tvalid_0's l2: 65.2938\n",
      "[173]\tvalid_0's l2: 65.1844\n",
      "[174]\tvalid_0's l2: 65.1153\n",
      "[175]\tvalid_0's l2: 65.01\n",
      "[176]\tvalid_0's l2: 64.9177\n",
      "[177]\tvalid_0's l2: 64.8091\n",
      "[178]\tvalid_0's l2: 64.7258\n",
      "[179]\tvalid_0's l2: 64.63\n",
      "[180]\tvalid_0's l2: 64.5626\n",
      "[181]\tvalid_0's l2: 64.4777\n",
      "[182]\tvalid_0's l2: 64.4137\n",
      "[183]\tvalid_0's l2: 64.3404\n",
      "[184]\tvalid_0's l2: 64.2499\n",
      "[185]\tvalid_0's l2: 64.1891\n",
      "[186]\tvalid_0's l2: 64.1104\n",
      "[187]\tvalid_0's l2: 64.0351\n",
      "[188]\tvalid_0's l2: 63.9697\n",
      "[189]\tvalid_0's l2: 63.8999\n",
      "[190]\tvalid_0's l2: 63.8335\n",
      "[191]\tvalid_0's l2: 63.7594\n",
      "[192]\tvalid_0's l2: 63.6877\n",
      "[193]\tvalid_0's l2: 63.6336\n",
      "[194]\tvalid_0's l2: 63.5858\n",
      "[195]\tvalid_0's l2: 63.5022\n",
      "[196]\tvalid_0's l2: 63.4346\n",
      "[197]\tvalid_0's l2: 63.3571\n",
      "[198]\tvalid_0's l2: 63.2913\n",
      "[199]\tvalid_0's l2: 63.2393\n",
      "[200]\tvalid_0's l2: 63.1701\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 63.1701\n",
      "Training Iteration:  200\n",
      "Train:\tValid:\t"
     ]
    }
   ],
   "source": [
    "score_cols = [\"mse\"]\n",
    "score_df = pd.DataFrame([])\n",
    "\n",
    "for cv_name, cv in cv_dict.items():\n",
    "    print(\"*\" * 10 + \"  \" + cv_name + \"  \" + \"*\" * 10)    \n",
    "    for d in depths:\n",
    "        print(\"*\" * 5 + \" Depth: \",d,\" \"+ \"*\" * 5)\n",
    "        new_lgb_params = lgb_params.copy()\n",
    "        new_lgb_params[\"max_depth\"] = d\n",
    "        model = LGBMRegressor(**new_lgb_params)\n",
    "        t_score = []\n",
    "        v_score = []        \n",
    "        for f,(t_idx, v_idx) in enumerate(cv.split(X, y, dates)):\n",
    "            print(\"Fold \"+str(f)+\" :\")\n",
    "            X_t, X_v = X[t_idx], X[v_idx]\n",
    "            y_t, y_v = y[t_idx], y[v_idx]\n",
    "            model.fit(X_t, y_t, eval_set =[(X_v, y_v)], early_stopping_rounds = 20, verbose=True)\n",
    "            iteration = model.best_iteration_\n",
    "            print(\"Training Iteration: \", iteration)\n",
    "            print(\"Train\",end=\":\\t\")\n",
    "            t_mse = utility(model, X_t, y_t)\n",
    "            print(\"Valid\",end=\":\\t\")\n",
    "            v_mse = utility(model, X_v, y_v)\n",
    "            t_score.append([t_mse,iteration])\n",
    "            v_score.append([v_mse,iteration])  \n",
    "        t_score_df = pd.DataFrame(t_score, columns = score_cols+[\"iteration\"])\n",
    "        v_score_df = pd.DataFrame(v_score, columns = score_cols+[\"iteration\"])\n",
    "        t_score_df[\"train\"] = True \n",
    "        t_score_df[\"cv\"] = cv_name\n",
    "        t_score_df[\"depth\"] = d\n",
    "        v_score_df[\"train\"] = False \n",
    "        v_score_df[\"cv\"] = cv_name\n",
    "        v_score_df[\"depth\"] = d\n",
    "        t_score_mean = t_score_df[score_cols].mean()\n",
    "        t_score_std = t_score_df[score_cols].std()\n",
    "        v_score_mean = v_score_df[score_cols].mean()\n",
    "        v_score_std = v_score_df[score_cols].std()\n",
    "        score_df = pd.concat([score_df, t_score_df, v_score_df],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
